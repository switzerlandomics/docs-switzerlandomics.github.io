<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="manifest" href="/site.webmanifest"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#edbe7a"><link rel="shortcut icon" href="/favicon.ico"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/browserconfig.xml"><meta name="theme-color" content="#ffffff"><title>Causal inference mosquito nets | Dev docs</title><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="Causal inference mosquito nets" /><meta name="author" content="Ref, Dylan Lawless" /><meta property="og:locale" content="en_US" /><meta name="description" content="Dev docs made with Jeykll using the Just the Docs theme." /><meta property="og:description" content="Dev docs made with Jeykll using the Just the Docs theme." /><link rel="canonical" href="http://localhost:4000/pages/causal_inference_whole_game.html" /><meta property="og:url" content="http://localhost:4000/pages/causal_inference_whole_game.html" /><meta property="og:site_name" content="Dev docs" /><meta property="og:type" content="website" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Causal inference mosquito nets" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Ref, Dylan Lawless"},"description":"Dev docs made with Jeykll using the Just the Docs theme.","headline":"Causal inference mosquito nets","url":"http://localhost:4000/pages/causal_inference_whole_game.html"}</script> <script type="text/javascript" defer src="/assets/js/mathjax-script-type.js"> </script> <script type="text/javascript" id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"> </script><body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"><title id="svg-external-link-title">(external link)</title><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-copy" viewBox="0 0 16 16"><title>Copy</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"><title>Copied</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"><path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg><div class="side-bar"><div class="site-header"> <a href="/" class="site-title lh-tight"> Dev docs </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a></div><nav aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a><li class="nav-list-item"><a href="/pages/bam2fastq.html" class="nav-list-link">BWA</a><li class="nav-list-item"><a href="/pages/bayesian_example1.html" class="nav-list-link">Bayes 1 probability in placenta previa</a><li class="nav-list-item"><a href="/pages/bayesian_example2.html" class="nav-list-link">Bayesian 2 probability in placenta previa</a><li class="nav-list-item"><a href="/pages/bayesian_genetic_carrier.html" class="nav-list-link">Bayesian discrete probability example in genetics</a><li class="nav-list-item"><a href="/pages/bayesian_mcmc_samplers.html" class="nav-list-link">Bayes MCMC samplers</a><li class="nav-list-item"><a href="/pages/bayesian_multiparameter_bioassay.html" class="nav-list-link">Bayes multiparameter bioassay demo</a><li class="nav-list-item"><a href="/pages/bayesian_multiparameter_models.html" class="nav-list-link">Bayes multiparameter models</a><li class="nav-list-item"><a href="/pages/benchmark_pipelines.html" class="nav-list-link">Benchmarking pipeline output</a><li class="nav-list-item"><a href="/pages/bevimed.html" class="nav-list-link">BeviMed</a><li class="nav-list-item"><a href="/pages/biomedit.html" class="nav-list-link">BioMedIT</a><li class="nav-list-item"><a href="/pages/bookmarks.html" class="nav-list-link">Bookmarks</a><li class="nav-list-item"><a href="/pages/bwa.html" class="nav-list-link">BWA</a><li class="nav-list-item"><a href="/pages/causal_inference_stats.html" class="nav-list-link">Causal inference stats</a><li class="nav-list-item active"><a href="/pages/causal_inference_whole_game.html" class="nav-list-link active">Causal inference mosquito nets</a><li class="nav-list-item"><a href="/pages/data_concepts.html" class="nav-list-link">Data concepts</a><li class="nav-list-item"><a href="/pages/data_stream.html" class="nav-list-link">Data stream</a><li class="nav-list-item"><a href="#" class="nav-list-expander" aria-label="toggle links in Design documents category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/pages/design_doc.html" class="nav-list-link">Design documents</a><ul class="nav-list"><li class="nav-list-item "><a href="/pages/design_PCA_SNV_INDEL_V1.html" class="nav-list-link">Design PCA SNV INDEL v1</a><li class="nav-list-item "><a href="/pages/design_dna_snvindel_v1.html" class="nav-list-link">Design DNA SNV INDEL v1</a><li class="nav-list-item "><a href="/pages/design_dna_snvindel_v1_release.html" class="nav-list-link">Design release DNA SNV INDEL v1</a><li class="nav-list-item "><a href="/pages/design_dna_snvindel_v2_release.html" class="nav-list-link">Design release DNA SNV INDEL v2</a><li class="nav-list-item "><a href="/pages/design_qv_snvindel_v1.html" class="nav-list-link">Design QV SNV INDEL v1</a><li class="nav-list-item "><a href="/pages/design_statistical_genomics_v1.html" class="nav-list-link">Design statistical genomics v1</a></ul><li class="nav-list-item"><a href="/pages/dna_annotation.html" class="nav-list-link">DNA annotation</a><li class="nav-list-item"><a href="/pages/dna_interpretation.html" class="nav-list-link">DNA interpretation</a><li class="nav-list-item"><a href="/pages/dna_qc.html" class="nav-list-link">DNA QC</a><li class="nav-list-item"><a href="/pages/docker_singularity.html" class="nav-list-link">Docker with singularity</a><li class="nav-list-item"><a href="/pages/fastp.html" class="nav-list-link">FASTP</a><li class="nav-list-item"><a href="/pages/fastq.html" class="nav-list-link">FASTQ format data</a><li class="nav-list-item"><a href="/pages/filter_vcf_bcftools.html" class="nav-list-link">Filter VCF with bcftools</a><li class="nav-list-item"><a href="/pages/financial_management.html" class="nav-list-link">Financial management</a><li class="nav-list-item"><a href="/pages/guru.html" class="nav-list-link">Guru variant interpretation</a><li class="nav-list-item"><a href="/pages/gwas.html" class="nav-list-link">GWAS analysis</a><li class="nav-list-item"><a href="/pages/hpc.html" class="nav-list-link">HPC infrastructure</a><li class="nav-list-item"><a href="/pages/inf_causal_metab_sem.html" class="nav-list-link">Inference of causal metabolite networks</a><li class="nav-list-item"><a href="/pages/layout.html" class="nav-list-link">Layout</a><li class="nav-list-item"><a href="/pages/mathjax.html" class="nav-list-link">MathJax config</a><li class="nav-list-item"><a href="/pages/mbdf_models.html" class="nav-list-link">MBDF models</a><li class="nav-list-item"><a href="/pages/mbdf_supervised.html" class="nav-list-link">MBDF supervised</a><li class="nav-list-item"><a href="/pages/mbdf_unsupervised.html" class="nav-list-link">MBDF unsupervised</a><li class="nav-list-item"><a href="/pages/metadata.html" class="nav-list-link">WGS metadata</a><li class="nav-list-item"><a href="/pages/metrics_bcftoolscounts.html" class="nav-list-link">Metrics Bcftools counts</a><li class="nav-list-item"><a href="/pages/metrics_bcftoolsstats.html" class="nav-list-link">Metrics Bcftools stats</a><li class="nav-list-item"><a href="/pages/metrics_collectwgsmetrics.html" class="nav-list-link">Metrics CollectWgsMetrics</a><li class="nav-list-item"><a href="/pages/multiblock_data_fusion.html" class="nav-list-link">Multiblock data fusion</a><li class="nav-list-item"><a href="/pages/panels_disease.html" class="nav-list-link">Panels disease gene</a><li class="nav-list-item"><a href="/pages/pca_biplot_1kg.html" class="nav-list-link">PCA biplot 1000genomes</a><li class="nav-list-item"><a href="/pages/pca_features.html" class="nav-list-link">PCA features</a><li class="nav-list-item"><a href="/pages/platform_updates.html" class="nav-list-link">Platform updates</a><li class="nav-list-item"><a href="/pages/precision_med.html" class="nav-list-link">Precision Medicine Unit (PMU)</a><li class="nav-list-item"><a href="/pages/present/presentations.html" class="nav-list-link">Presentations</a><li class="nav-list-item"><a href="/pages/read_group.html" class="nav-list-link">Read group</a><li class="nav-list-item"><a href="/pages/ref.html" class="nav-list-link">Reference genome</a><li class="nav-list-item"><a href="/pages/rl_finte_mdp.html" class="nav-list-link">RL finite MDP</a><li class="nav-list-item"><a href="/pages/slurm_manager.html" class="nav-list-link">SLURM monitoring</a><li class="nav-list-item"><a href="/pages/slurm_sbatch.html" class="nav-list-link">SLURM sbatch headers</a><li class="nav-list-item"><a href="/pages/stats_altman_bland_analysis_of_methods.html" class="nav-list-link">Stats Analysis of methods</a><li class="nav-list-item"><a href="/pages/stats_altman_bland_ci_from_p.html" class="nav-list-link">Stats CI from P</a><li class="nav-list-item"><a href="/pages/stats_altman_bland_correlation.html" class="nav-list-link">Stats Correlation, regression and repeated data</a><li class="nav-list-item"><a href="/pages/stats_altman_bland_odds_ratios.html" class="nav-list-link">Stats Odds ratios, SE & CI</a><li class="nav-list-item"><a href="/pages/stats_altman_bland_roc_curve.html" class="nav-list-link">Stats Receiver operating characteristic plots</a><li class="nav-list-item"><a href="/pages/stats_altman_bland_sensitivity_specificity.html" class="nav-list-link">Stats Sensitivity and specificity</a><li class="nav-list-item"><a href="/pages/storage_architecture_plan.html" class="nav-list-link">Storage architecture plan</a><li class="nav-list-item"><a href="/pages/storage_estimates.html" class="nav-list-link">Storage estimates</a><li class="nav-list-item"><a href="/pages/storage_use_sync_and_versioning.html" class="nav-list-link">Storage, usage, and Git practices</a><li class="nav-list-item"><a href="/pages/style.html" class="nav-list-link">Style page guide</a><li class="nav-list-item"><a href="/pages/style_writing.html" class="nav-list-link">Style writing guide</a><li class="nav-list-item"><a href="/pages/sv.html" class="nav-list-link">Structural variation detection</a><li class="nav-list-item"><a href="/pages/synth_data.html" class="nav-list-link">Synthetic data</a><li class="nav-list-item"><a href="/pages/variables.html" class="nav-list-link">Variables</a><li class="nav-list-item"><a href="/pages/Phoenix_Sepsis_Score_logic.html" class="nav-list-link">Sepsis score: Phoenix</a><li class="nav-list-item"><a href="/pages/vcf.html" class="nav-list-link">VCF - Variant Call Format</a><li class="nav-list-item"><a href="/pages/vcf_gvcf.html" class="nav-list-link">VCF and gVCF</a><li class="nav-list-item"><a href="/pages/virtual_panels.html" class="nav-list-link">Virtual gene panels</a><li class="nav-list-item"><a href="/pages/vsat.html" class="nav-list-link">VSAT with SKAT</a><li class="nav-list-item"><a href="/pages/vsat_setID.html" class="nav-list-link">SetID for VSAT</a><li class="nav-list-item"><a href="/pages/variant_concept.html" class="nav-list-link">Variant to RDF concept</a><li class="nav-list-item"><a href="/pages/acat.html" class="nav-list-link">ACAT</a><li class="nav-list-item"><a href="/pages/acmg_criteria_table_main.html" class="nav-list-link">ACMG criteria</a><li class="nav-list-item"><a href="/pages/aggregate_multiplex.html" class="nav-list-link">Aggregate multiplexed data</a><li class="nav-list-item"><a href="/pages/annotation_table.html" class="nav-list-link">Annotation table</a><li class="nav-list-item"><a href="/pages/documentation_log.html" class="nav-list-link">Documentation log</a></ul></nav><footer class="site-footer"> Maintained by <a href="https://github.com/DylanLawless">Dylan Lawless</a> for <a href="https://switzerlandomics.ch">SwitzerlandOmics.ch</a>.</footer></div><div class="main" id="top"><div id="main-header" class="main-header"><div class="search"><div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Dev docs" aria-label="Search Dev docs" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label></div><div id="search-results" class="search-results"></div></div><nav aria-label="Auxiliary" class="aux-nav"><ul class="aux-nav-list"><li class="aux-nav-list-item"> <a href="https://github.com/docs-switzerlandomics.github.io" class="site-button" > Github </a><li class="aux-nav-list-item"> <a href="https://switzerlandomics.ch" class="site-button" > SwitzerlandOmics.ch </a></ul></nav></div><div id="main-content-wrap" class="main-content-wrap"><div id="main-content" class="main-content" role="main"><h1 id="1-causal-inference---mosquito-nets-and-malaria"> <a href="#1-causal-inference---mosquito-nets-and-malaria" class="anchor-heading" aria-labelledby="1-causal-inference---mosquito-nets-and-malaria"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1 Causal inference - mosquito nets and malaria</h1><p>Last update:</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] "2024-12-31"
</code></pre></div></div><p>This doc was built with: <code class="language-plaintext highlighter-rouge">rmarkdown::render("causal_inference_whole_game.Rmd", output_file = "../pages/causal_inference_whole_game.md")</code></p><p class="warning">This text is largely copied directly from the following source while we build an example closer to our needs. Please see the original source as follows.</p><p>This example is described in the textbook: Causal Inference in R, by Malcolm Barrett, Lucy D’Agostino McGowan, and Travis Gerke. <a href="https://www.r-causal.org">https://www.r-causal.org</a>, chapter 2.</p><p>We will use simulated data to answer a more specific question: Does using insecticide-treated bed nets compared to no nets decrease the risk of contracting malaria after 1 year? Data <a href="https://evalsp21.classes.andrewheiss.com/example/matching-ipw/#program-background">simulated by Dr. Andrew Heiss</a>:</p><blockquote><p>…researchers are interested in whether using mosquito nets decreases an individual’s risk of contracting malaria. They have collected data from 1,752 households in an unnamed country and have variables related to environmental factors, individual health, and household characteristics. The data is <strong>not experimental</strong>—researchers have no control over who uses mosquito nets, and individual households make their own choices over whether to apply for free nets or buy their own nets, as well as whether they use the nets if they have them.</p></blockquote><p>This data includes a variable that measures the likelihood of contracting malaria, something we wouldn’t likely have in real life. This let’s us know the actual effect size to understand the methods better. The simulated data is in <code class="language-plaintext highlighter-rouge">net_data</code> from the {<a href="https://github.com/r-causal/causalworkshop">causalworkshop</a>} package, which includes ten variables:</p><ul><li><code class="language-plaintext highlighter-rouge">id</code> : an ID variable<li><code class="language-plaintext highlighter-rouge">net</code> and <code class="language-plaintext highlighter-rouge">net_num</code> : a binary variable indicating if the participant used a net (1) or didn’t use a net (0)<li><code class="language-plaintext highlighter-rouge">malaria_risk</code> : risk of malaria scale ranging from 0-100<li><code class="language-plaintext highlighter-rouge">income</code> : weekly income, measured in dollars<li><code class="language-plaintext highlighter-rouge">health</code> : a health score scale ranging from 0–100<li><code class="language-plaintext highlighter-rouge">household</code> : number of people living in the household<li><code class="language-plaintext highlighter-rouge">eligible</code> : a binary variable indicating if the household is eligible for the free net program.<li><code class="language-plaintext highlighter-rouge">temperature</code> : the average temperature at night, in Celsius<li><code class="language-plaintext highlighter-rouge">resistance</code> : Insecticide resistance of local mosquitoes. A scale of 0–100, with higher values indicating higher resistance.</ul><p>The distribution of malaria risk appears to be quite different by net usage.</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># devtools::install_github("r-causal/causalworkshop")</span><span class="w">
</span></code></pre></div></div><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">tidyverse</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">causalworkshop</span><span class="p">)</span><span class="w">
</span><span class="n">net_data</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">malaria_risk</span><span class="p">,</span><span class="w"> </span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">net</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_density</span><span class="p">(</span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.8</span><span class="p">)</span><span class="w">
</span></code></pre></div></div><div class="figure"> <img src="../pages/causal_inference_whole_game_files/figure-gfm/fig-malaria-risk-density-1.png" alt="A density plot of malaria risk for those who did and did not use nets. The risk of malaria is lower for those who use nets." /><p class="caption"> <span id="fig:fig-malaria-risk-density"></span>Figure 1.1: A density plot of malaria risk for those who did and did not use nets. The risk of malaria is lower for those who use nets.</p></div><p>In figure <a href="#fig:fig-malaria-risk-density">1.1</a>, the density of those who used nets is to the left of those who did not use nets. The mean difference in malaria risk is about 16.4, suggesting net use might be protective against malaria.</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">net_data</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">group_by</span><span class="p">(</span><span class="n">net</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">summarize</span><span class="p">(</span><span class="n">malaria_risk</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">malaria_risk</span><span class="p">))</span><span class="w">
</span></code></pre></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 2 × 2
##   net   malaria_risk
##   &lt;lgl&gt;        &lt;dbl&gt;
## 1 FALSE         43.9
## 2 TRUE          27.5
</code></pre></div></div><p>And that’s what we see with simple linear regression, as well, as we would expect.</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">broom</span><span class="p">)</span><span class="w">
</span><span class="n">net_data</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">lm</span><span class="p">(</span><span class="n">malaria_risk</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">net</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">_</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">tidy</span><span class="p">()</span><span class="w">
</span></code></pre></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 2 × 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)     43.9     0.377     116.  0       
## 2 netTRUE        -16.4     0.741     -22.1 1.10e-95
</code></pre></div></div><h2 id="11-draw-our-assumptions-using-a-causal-diagram"> <a href="#11-draw-our-assumptions-using-a-causal-diagram" class="anchor-heading" aria-labelledby="11-draw-our-assumptions-using-a-causal-diagram"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.1 Draw our assumptions using a causal diagram</h2><p>The problem that we face is that other factors may be responsible for the effect we’re seeing. In this example, we’ll focus on confounding: a common cause of net usage and malaria will bias the effect we see unless we account for it somehow. One of the best ways to determine which variables we need to account for is to use a causal diagram. These diagrams, also called <strong>causal directed acyclic graphs (DAGs)</strong>, visualize the assumptions that we’re making about the causal relationships between the exposure, outcome, and other variables we think might be related.</p><p>Here’s the DAG that we’re proposing for this question.</p><div class="figure"> <img src="../pages/causal_inference_whole_game_files/figure-gfm/fig-net-data-dag-1.png" alt="A proposed causal diagram of the effect of bed net use on malaria. This directed acyclic graph (DAG) states our assumption that bed net use causes a reduction in malaria risk. It also says that we assume: malaria risk is impacted by net usage, income, health, temperature, and insecticide resistance; net usage is impacted by income, health, temperature, eligibility for the free net program, and the number of people in a household; eligibility for the free net programs is impacted by income and the number of people in a household; and health is impacted by income." /><p class="caption"> <span id="fig:fig-net-data-dag"></span>Figure 1.2: A proposed causal diagram of the effect of bed net use on malaria. This directed acyclic graph (DAG) states our assumption that bed net use causes a reduction in malaria risk. It also says that we assume: malaria risk is impacted by net usage, income, health, temperature, and insecticide resistance; net usage is impacted by income, health, temperature, eligibility for the free net program, and the number of people in a household; eligibility for the free net programs is impacted by income and the number of people in a household; and health is impacted by income.</p></div><p>We’ll explore how to create and analyze DAGs in @sec-dags.</p><p>In DAGs, each point represents a variable, and each arrow represents a cause. In other words, this diagram declares what we think the causal relationships are between these variables. In figure <a href="#fig:fig-net-data-dag">1.2</a>, we’re saying that we believe:</p><ul><li>Malaria risk is causally impacted by net usage, income, health, temperature, and insecticide resistance.<li>Net usage is causally impacted by income, health, temperature, eligibility for the free net program, and the number of people in a household.<li>Eligibility for the free net programs is determined by income and the number of people in a household.<li>Health is causally impacted by income.</ul><p>You may agree or disagree with some of these assertions. That’s a good thing! Laying bare our assumptions allows us to consider the scientific credibility of our analysis. Another benefit of using DAGs is that, thanks to their mathematics, we can determine precisely the subset of variables we need to account for if we assume this DAG is correct.</p><p class="note"><strong>Assembling DAGs</strong> In this exercise, we’re providing you with a reasonable DAG based on knowledge of how the data were generated. In real life, setting up a DAG is a challenge requiring deep thought, domain expertise, and (often) collaboration between several experts.</p><p>The chief problem we’re dealing with is that, when we analyze the data we’re working with, we see the impact of net usage on malaria risk <em>and of all these other relationships</em>. In DAG terminology, we have more than one open causal pathway. If this DAG is correct, we have <em>eight</em> causal pathways: the path between net usage and malaria risk and seven other <em>confounding</em> pathways.</p><div class="figure"> <img src="../pages/causal_inference_whole_game_files/figure-gfm/fig-net-data-confounding-1.png" alt="In the proposed DAG, there are eight open pathways that contribute to the causal effect seen in the naive regression: the true effect (in green) of net usage on malaria risk and seven other confounding pathways (in orange). The naive estimate is wrong because it is a composite of all these effects." /><p class="caption"> <span id="fig:fig-net-data-confounding"></span>Figure 1.3: In the proposed DAG, there are eight open pathways that contribute to the causal effect seen in the naive regression: the true effect (in green) of net usage on malaria risk and seven other confounding pathways (in orange). The naive estimate is wrong because it is a composite of all these effects.</p></div><p>When we calculate a naive linear regression that only includes net usage and malaria risk, the effect we see is incorrect because the seven other confounding pathways in figure <a href="#fig:fig-net-data-confounding">1.3</a> distort it. In DAG terminology, we need to <em>block</em> these open pathways that distort the causal estimate we’re after. (We can block paths through several techniques, including stratification, matching, weighting, and more. We’ll see several methods throughout the book.) Luckily, by specifying a DAG, we can precisely determine the variables we need to control for. For this DAG, we need to control for three variables: health, income, and temperature. These three variables are a <em>minimal adjustment set</em>, the minimum set (or sets) of variables you need to block all confounding pathways. We’ll discuss adjustment sets further in @sec-dags.</p><h2 id="12-model-our-assumptions"> <a href="#12-model-our-assumptions" class="anchor-heading" aria-labelledby="12-model-our-assumptions"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.2 Model our assumptions</h2><p>We’ll use a technique called <strong>inverse probability weighting (IPW)</strong> to control for these variables, which we’ll discuss in detail in @sec-using-ps. We’ll use logistic regression to predict the probability of treatment—the propensity score. Then, we’ll calculate inverse probability weights to apply to the linear regression model we fit above. The propensity score model includes the exposure—net use—as the dependent variable and the minimal adjustment set as the independent variables.</p><p class="note"><strong>Modeling the functional form</strong> Generally speaking, we want to lean on domain expertise and good modeling practices to fit the propensity score model. For instance, we may want to allow continuous confounders to be non-linear using splines, or we may want to add essential interactions between confounders. Because these are simulated data, we know we don’t need these extra parameters (so we’ll skip them), but in practice, you often do. We’ll discuss this more in @sec-using-ps.</p><p>The propensity score model is a logistic regression model with the formula <code class="language-plaintext highlighter-rouge">net ~ income + health + temperature</code>, which predicts the probability of bed net usage based on the confounders income, health, and temperature.</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">propensity_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">glm</span><span class="p">(</span><span class="w">
  </span><span class="n">net</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">income</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">health</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">temperature</span><span class="p">,</span><span class="w">
  </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">net_data</span><span class="p">,</span><span class="w">
  </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binomial</span><span class="p">()</span><span class="w">
</span><span class="p">)</span><span class="w">

</span><span class="c1"># the first six propensity scores</span><span class="w">
</span><span class="n">head</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="n">propensity_model</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"response"</span><span class="p">))</span><span class="w">
</span></code></pre></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>##      1      2      3      4      5      6 
## 0.2464 0.2178 0.3230 0.2307 0.2789 0.3060
</code></pre></div></div><p>We can use propensity scores to control for confounding in various ways. In this example, we’ll focus on weighting. In particular, we’ll compute the inverse probability weight for the <strong>average treatment effect (ATE)</strong>. The ATE represents a particular causal question: what if <em>everyone</em> in the study used bed nets vs. what if <em>no one</em> in the study used bed nets?</p><p>To calculate the ATE, we’ll use the broom and propensity packages. broom’s <code class="language-plaintext highlighter-rouge">augment()</code> function extracts prediction-related information from the model and joins it to the data. propensity’s <code class="language-plaintext highlighter-rouge">wt_ate()</code> function calculates the inverse probability weight given the propensity score and exposure.</p><p>For inverse probability weighting, the ATE weight is the inverse of probability of receiving the treatment you actually received. In other words, if you used a bed net, the ATE weight is the inverse of the probability that you used a net, and if you did <em>not</em> use a net, it is the the inverse of the probability that you did <em>not</em> use a net.</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">broom</span><span class="p">)</span><span class="w">
</span><span class="n">library</span><span class="p">(</span><span class="n">propensity</span><span class="p">)</span><span class="w">
</span><span class="n">net_data_wts</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">propensity_model</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">augment</span><span class="p">(</span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">net_data</span><span class="p">,</span><span class="w"> </span><span class="n">type.predict</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"response"</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="c1"># .fitted is the value predicted by the model</span><span class="w">
  </span><span class="c1"># for a given observation</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">wts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">wt_ate</span><span class="p">(</span><span class="n">.fitted</span><span class="p">,</span><span class="w"> </span><span class="n">net</span><span class="p">))</span><span class="w">

</span><span class="n">net_data_wts</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">select</span><span class="p">(</span><span class="n">net</span><span class="p">,</span><span class="w"> </span><span class="n">.fitted</span><span class="p">,</span><span class="w"> </span><span class="n">wts</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">head</span><span class="p">()</span><span class="w">
</span></code></pre></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 6 × 3
##   net   .fitted   wts
##   &lt;lgl&gt;   &lt;dbl&gt; &lt;dbl&gt;
## 1 FALSE   0.246  1.33
## 2 FALSE   0.218  1.28
## 3 FALSE   0.323  1.48
## 4 FALSE   0.231  1.30
## 5 FALSE   0.279  1.39
## 6 FALSE   0.306  1.44
</code></pre></div></div><p><code class="language-plaintext highlighter-rouge">wts</code> represents the amount each observation will be up-weighted or down-weighted in the outcome model we will soon fit. For instance, the 16th household used a bed net and had a predicted probability of 0.41. That’s a pretty low probability considering they did, in fact, use a net, so their weight is higher at 2.42. In other words, this household will be up-weighted compared to the naive linear model we fit above. The first household did <em>not</em> use a bed net; they’re predicted probability of net use was 0.25 (or put differently, a predicted probability of <em>not</em> using a net of 0.75). That’s more in line with their observed value of <code class="language-plaintext highlighter-rouge">net</code>, but there’s still some predicted probability of using a net, so their weight is 1.28.</p><h2 id="13-diagnose-our-models"> <a href="#13-diagnose-our-models" class="anchor-heading" aria-labelledby="13-diagnose-our-models"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.3 Diagnose our models</h2><p>The goal of propensity score weighting is to weight the population of observations such that the distribution of confounders is balanced between the exposure groups. Put another way, we are, in principle, removing the arrows between the confounders and exposure in the DAG, so that the confounding paths no longer distort our estimates. Here’s the distribution of the propensity score by group, created by <code class="language-plaintext highlighter-rouge">geom_mirror_histogram()</code> from the halfmoon package for assessing balance in propensity score models:</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">halfmoon</span><span class="p">)</span><span class="w">
</span><span class="n">ggplot</span><span class="p">(</span><span class="n">net_data_wts</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">.fitted</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_mirror_histogram</span><span class="p">(</span><span class="w">
    </span><span class="n">aes</span><span class="p">(</span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">net</span><span class="p">),</span><span class="w">
    </span><span class="n">bins</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">50</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">scale_y_continuous</span><span class="p">(</span><span class="n">labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">abs</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"propensity score"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div><div class="figure"> <img src="../pages/causal_inference_whole_game_files/figure-gfm/fig-mirror-histogram-net-data-unweighted-1.png" alt="A mirrored histogram of the propensity scores of those who used nets (top, blue) versus those who did not use nets (bottom, orange). The range of propensity scores is similar between groups, with those who used nets slightly to the left of those who didn't, but the shapes of the distribution are different." /><p class="caption"> <span id="fig:fig-mirror-histogram-net-data-unweighted"></span>Figure 1.4: A mirrored histogram of the propensity scores of those who used nets (top, blue) versus those who did not use nets (bottom, orange). The range of propensity scores is similar between groups, with those who used nets slightly to the left of those who didn’t, but the shapes of the distribution are different.</p></div><p>The weighted propensity score creates a pseudo-population where the distributions are much more similar:</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ggplot</span><span class="p">(</span><span class="n">net_data_wts</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">.fitted</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_mirror_histogram</span><span class="p">(</span><span class="w">
    </span><span class="n">aes</span><span class="p">(</span><span class="n">group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">net</span><span class="p">),</span><span class="w">
    </span><span class="n">bins</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">50</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_mirror_histogram</span><span class="p">(</span><span class="w">
    </span><span class="n">aes</span><span class="p">(</span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">net</span><span class="p">,</span><span class="w"> </span><span class="n">weight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">wts</span><span class="p">),</span><span class="w">
    </span><span class="n">bins</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">50</span><span class="p">,</span><span class="w">
    </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">.5</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">scale_y_continuous</span><span class="p">(</span><span class="n">labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">abs</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"propensity score"</span><span class="p">)</span><span class="w">
</span></code></pre></div></div><div class="figure"> <img src="../pages/causal_inference_whole_game_files/figure-gfm/fig-mirror-histogram-net-data-weighted-1.png" alt="A mirrored histogram of the propensity scores of those who used nets (top, blue) versus those who did not use nets (bottom, orange). The shaded region represents the unweighted distribution, and the colored region represents the weighted distributions. The ATE weights up-weight the groups to be similar in range and shape of the distribution of propensity scores." /><p class="caption"> <span id="fig:fig-mirror-histogram-net-data-weighted"></span>Figure 1.5: A mirrored histogram of the propensity scores of those who used nets (top, blue) versus those who did not use nets (bottom, orange). The shaded region represents the unweighted distribution, and the colored region represents the weighted distributions. The ATE weights up-weight the groups to be similar in range and shape of the distribution of propensity scores.</p></div><p>In this example, the unweighted distributions are not awful—the shapes are somewhat similar here, and they overlap quite a bit—but the weighted distributions in figure <a href="#fig:fig-mirror-histogram-net-data-unweighted">1.4</a> are much more similar.</p><p class="note"><strong>Unmeasured confounding</strong> Propensity score weighting and most other causal inference techniques only help with <em>observed</em> confounders—ones that we model correctly, at that. Unfortunately, we still may have unmeasured confounding, which we’ll discuss below. Randomization is one causal inference technique that <em>does</em> deal with unmeasured confounding, one of the reasons it is so powerful.</p><p>We might also want to know how well-balanced the groups are by each confounder. One way to do this is to calculate the <strong>standardized mean differences (SMDs)</strong> for each confounder with and without weights. We’ll calculate the SMDs with <code class="language-plaintext highlighter-rouge">tidy_smd()</code> then plot them with <code class="language-plaintext highlighter-rouge">geom_love()</code>.</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">tidy_smd</span><span class="p">(</span><span class="w">
  </span><span class="n">net_data_wts</span><span class="p">,</span><span class="w">
  </span><span class="nf">c</span><span class="p">(</span><span class="n">income</span><span class="p">,</span><span class="w"> </span><span class="n">health</span><span class="p">,</span><span class="w"> </span><span class="n">temperature</span><span class="p">),</span><span class="w">
  </span><span class="n">.group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">net</span><span class="p">,</span><span class="w">
  </span><span class="n">.wts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">wts</span><span class="w">
</span><span class="p">)</span><span class="w">

</span><span class="n">ggplot</span><span class="p">(</span><span class="w">
  </span><span class="n">plot_df</span><span class="p">,</span><span class="w">
  </span><span class="n">aes</span><span class="p">(</span><span class="w">
    </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">abs</span><span class="p">(</span><span class="n">smd</span><span class="p">),</span><span class="w">
    </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">variable</span><span class="p">,</span><span class="w">
    </span><span class="n">group</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">method</span><span class="p">,</span><span class="w">
    </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">method</span><span class="w">
  </span><span class="p">)</span><span class="w">
</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_love</span><span class="p">()</span><span class="w">
</span></code></pre></div></div><div class="figure"> <img src="../pages/causal_inference_whole_game_files/figure-gfm/fig-love-plot-net-data-1.png" alt="A love plot representing the standardized mean differences (SMD) between exposure groups of three confounders: temperature, income, and health. Before weighting, there are considerable differences in the groups. After weighting, the confounders are much more balanced between groups." /><p class="caption"> <span id="fig:fig-love-plot-net-data"></span>Figure 1.6: A love plot representing the standardized mean differences (SMD) between exposure groups of three confounders: temperature, income, and health. Before weighting, there are considerable differences in the groups. After weighting, the confounders are much more balanced between groups.</p></div><p>A standard guideline is that balanced confounders should have an SMD of less than 0.1 on the absolute scale. 0.1 is just a rule of thumb, but if we follow it, the variables in figure <a href="#fig:fig-love-plot-net-data">1.6</a> are well-balanced after weighting (and unbalanced before weighting).</p><p>Before we apply the weights to the outcome model, let’s check their overall distribution for extreme weights. Extreme weights can destabilize the estimate and variance in the outcome model, so we want to be aware of it. We’ll also discuss several other types of weights that are less prone to this issue in @sec-estimands.</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">net_data_wts</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">wts</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_density</span><span class="p">(</span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"#CC79A7"</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">NA</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.8</span><span class="p">)</span><span class="w">
</span></code></pre></div></div><div class="figure"> <img src="../pages/causal_inference_whole_game_files/figure-gfm/fig-ate-density-net-data-1.png" alt="A density plot of the average treatment effect (ATE) weights. The plot is skewed, with higher values towards 8. This may indicate a problem with the model, but the weights aren't so extreme to destabilize the variance of the estimate." /><p class="caption"> <span id="fig:fig-ate-density-net-data"></span>Figure 1.7: A density plot of the average treatment effect (ATE) weights. The plot is skewed, with higher values towards 8. This may indicate a problem with the model, but the weights aren’t so extreme to destabilize the variance of the estimate.</p></div><p>The weights in figure <a href="#fig:fig-ate-density-net-data">1.7</a> are skewed, but there are no outrageous values. If we saw extreme weights, we might try trimming or stabilizing them, or consider calculating an effect for a different estimand, which we’ll discuss in @sec-estimands. It doesn’t look like we need to do that here, however.</p><h2 id="14-estimate-the-causal-effect"> <a href="#14-estimate-the-causal-effect" class="anchor-heading" aria-labelledby="14-estimate-the-causal-effect"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.4 Estimate the causal effect</h2><p>We’re now ready to use the ATE weights to (attempt to) account for confounding in the naive linear regression model. Fitting such a model is pleasantly simple in this case: we fit the same model as before but with <code class="language-plaintext highlighter-rouge">weights = wts</code>, which will incorporate the inverse probability weights.</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">net_data_wts</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">lm</span><span class="p">(</span><span class="n">malaria_risk</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">net</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">_</span><span class="p">,</span><span class="w"> </span><span class="n">weights</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">wts</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">tidy</span><span class="p">(</span><span class="n">conf.int</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">)</span><span class="w">
</span></code></pre></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 2 × 7
##   term   estimate std.error statistic  p.value conf.low
##   &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Inte…     42.7     0.442      96.7 0            41.9
## 2 netTR…    -12.5     0.624     -20.1 5.50e-81    -13.8
## # ℹ 1 more variable: conf.high &lt;dbl&gt;
</code></pre></div></div><p>The estimate for the average treatment effect is -12.5 (95% CI -13.8, -11.3). Unfortunately, the confidence intervals we’re using are wrong because they don’t account for the uncertainty in estimating the weights. Generally, confidence intervals for propensity score weighted models will be too narrow unless we account for this uncertainty. The nominal coverage of the confidence intervals will thus be wrong (they aren’t 95% CIs because their coverage is much lower than 95%) and may lead to misinterpretation.</p><p>We’ve got several ways to address this problem, which we’ll discuss in detail in @sec-outcome-model, including the bootstrap, robust standard errors, and manually accounting for the estimation procedure with empirical sandwich estimators. For this example, we’ll use the bootstrap, a flexible tool that calculates distributions of parameters using re-sampling. The bootstrap is a useful tool for many causal models where closed-form solutions to problems (particularly standard errors) don’t exist or when we want to avoid parametric assumptions inherent to many such solutions; see @sec-appendix-bootstrap for a description of what the bootstrap is and how it works. We’ll use the rsample package from the tidymodels ecosystem to work with bootstrap samples.</p><p>Because the bootstrap is so flexible, we need to think carefully about the sources of uncertainty in the statistic we’re calculating. It might be tempting to write a function like this to fit the statistic we’re interested in (the point estimate for <code class="language-plaintext highlighter-rouge">netTRUE</code>):</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">rsample</span><span class="p">)</span><span class="w">

</span><span class="n">fit_ipw_not_quite_rightly</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">.split</span><span class="p">,</span><span class="w"> </span><span class="n">...</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="c1"># get bootstrapped data frame</span><span class="w">
  </span><span class="n">.df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.data.frame</span><span class="p">(</span><span class="n">.split</span><span class="p">)</span><span class="w">

  </span><span class="c1"># fit ipw model</span><span class="w">
  </span><span class="n">lm</span><span class="p">(</span><span class="n">malaria_risk</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">net</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">.df</span><span class="p">,</span><span class="w"> </span><span class="n">weights</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">wts</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
    </span><span class="n">tidy</span><span class="p">()</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div><p>However, this function won’t give us the correct confidence intervals because it treats the inverse probability weights as fixed values. They’re not, of course; we just estimated them using logistic regression! We need to account for this uncertainty by bootstrapping the <em>entire modeling process</em>. For every bootstrap sample, we need to fit the propensity score model, calculate the inverse probability weights, then fit the weighted outcome model.</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">rsample</span><span class="p">)</span><span class="w">

</span><span class="n">fit_ipw</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">.split</span><span class="p">,</span><span class="w"> </span><span class="n">...</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="c1"># get bootstrapped data frame</span><span class="w">
  </span><span class="n">.df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">as.data.frame</span><span class="p">(</span><span class="n">.split</span><span class="p">)</span><span class="w">

  </span><span class="c1"># fit propensity score model</span><span class="w">
  </span><span class="n">propensity_model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">glm</span><span class="p">(</span><span class="w">
    </span><span class="n">net</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">income</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">health</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">temperature</span><span class="p">,</span><span class="w">
    </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">.df</span><span class="p">,</span><span class="w">
    </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">binomial</span><span class="p">()</span><span class="w">
  </span><span class="p">)</span><span class="w">

  </span><span class="c1"># calculate inverse probability weights</span><span class="w">
  </span><span class="n">.df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">propensity_model</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
    </span><span class="n">augment</span><span class="p">(</span><span class="n">type.predict</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"response"</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">.df</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
    </span><span class="n">mutate</span><span class="p">(</span><span class="n">wts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">wt_ate</span><span class="p">(</span><span class="n">.fitted</span><span class="p">,</span><span class="w"> </span><span class="n">net</span><span class="p">))</span><span class="w">

  </span><span class="c1"># fit correctly bootstrapped ipw model</span><span class="w">
  </span><span class="n">lm</span><span class="p">(</span><span class="n">malaria_risk</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">net</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">.df</span><span class="p">,</span><span class="w"> </span><span class="n">weights</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">wts</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
    </span><span class="n">tidy</span><span class="p">()</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div><p>Now that we know precisely how to calculate the estimate for each iteration let’s create the bootstrapped dataset with rsample’s <code class="language-plaintext highlighter-rouge">bootstraps()</code> function. The <code class="language-plaintext highlighter-rouge">times</code> argument determines how many bootstrapped datasets to create; we’ll do 1,000.</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bootstrapped_net_data</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">bootstraps</span><span class="p">(</span><span class="w">
  </span><span class="n">net_data</span><span class="p">,</span><span class="w">
  </span><span class="n">times</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1000</span><span class="p">,</span><span class="w">
  </span><span class="c1"># required to calculate CIs later</span><span class="w">
  </span><span class="n">apparent</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="w">
</span><span class="p">)</span><span class="w">

</span><span class="n">bootstrapped_net_data</span><span class="w">
</span></code></pre></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # Bootstrap sampling with apparent sample 
## # A tibble: 1,001 × 2
##    splits             id           
##    &lt;list&gt;             &lt;chr&gt;        
##  1 &lt;split [1752/646]&gt; Bootstrap0001
##  2 &lt;split [1752/637]&gt; Bootstrap0002
##  3 &lt;split [1752/621]&gt; Bootstrap0003
##  4 &lt;split [1752/630]&gt; Bootstrap0004
##  5 &lt;split [1752/644]&gt; Bootstrap0005
##  6 &lt;split [1752/650]&gt; Bootstrap0006
##  7 &lt;split [1752/631]&gt; Bootstrap0007
##  8 &lt;split [1752/627]&gt; Bootstrap0008
##  9 &lt;split [1752/637]&gt; Bootstrap0009
## 10 &lt;split [1752/631]&gt; Bootstrap0010
## # ℹ 991 more rows
</code></pre></div></div><p>The result is a nested data frame: each <code class="language-plaintext highlighter-rouge">splits</code> object contains metadata that rsample uses to subset the bootstrap samples for each of the 1,000 samples. We actually have 1,001 rows because <code class="language-plaintext highlighter-rouge">apparent = TRUE</code> keeps a copy of the original data frame, as well, which is needed for some times of confidence interval calculations. Next, we’ll run <code class="language-plaintext highlighter-rouge">fit_ipw()</code> 1,001 times to create a distribution for <code class="language-plaintext highlighter-rouge">estimate</code>. At its heart, the calculation we’re doing is</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fit_ipw</span><span class="p">(</span><span class="n">bootstrapped_net_data</span><span class="o">$</span><span class="n">splits</span><span class="p">[[</span><span class="n">n</span><span class="p">]])</span><span class="w">
</span></code></pre></div></div><p>Where <em>n</em> is one of 1,001 indices. We’ll use purrr’s <code class="language-plaintext highlighter-rouge">map()</code> function to iterate across each <code class="language-plaintext highlighter-rouge">split</code> object.</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ipw_results</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">bootstrapped_net_data</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">mutate</span><span class="p">(</span><span class="n">boot_fits</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">map</span><span class="p">(</span><span class="n">splits</span><span class="p">,</span><span class="w"> </span><span class="n">fit_ipw</span><span class="p">))</span><span class="w">

</span><span class="n">ipw_results</span><span class="w">
</span></code></pre></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # Bootstrap sampling with apparent sample 
## # A tibble: 1,001 × 3
##    splits             id            boot_fits       
##    &lt;list&gt;             &lt;chr&gt;         &lt;list&gt;          
##  1 &lt;split [1752/646]&gt; Bootstrap0001 &lt;tibble [2 × 5]&gt;
##  2 &lt;split [1752/637]&gt; Bootstrap0002 &lt;tibble [2 × 5]&gt;
##  3 &lt;split [1752/621]&gt; Bootstrap0003 &lt;tibble [2 × 5]&gt;
##  4 &lt;split [1752/630]&gt; Bootstrap0004 &lt;tibble [2 × 5]&gt;
##  5 &lt;split [1752/644]&gt; Bootstrap0005 &lt;tibble [2 × 5]&gt;
##  6 &lt;split [1752/650]&gt; Bootstrap0006 &lt;tibble [2 × 5]&gt;
##  7 &lt;split [1752/631]&gt; Bootstrap0007 &lt;tibble [2 × 5]&gt;
##  8 &lt;split [1752/627]&gt; Bootstrap0008 &lt;tibble [2 × 5]&gt;
##  9 &lt;split [1752/637]&gt; Bootstrap0009 &lt;tibble [2 × 5]&gt;
## 10 &lt;split [1752/631]&gt; Bootstrap0010 &lt;tibble [2 × 5]&gt;
## # ℹ 991 more rows
</code></pre></div></div><p>The result is another nested data frame with a new column, <code class="language-plaintext highlighter-rouge">boot_fits</code>. Each element of <code class="language-plaintext highlighter-rouge">boot_fits</code> is the result of the IPW for the bootstrapped dataset. For example, in the first bootstrapped data set, the IPW results were:</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ipw_results</span><span class="o">$</span><span class="n">boot_fits</span><span class="p">[[</span><span class="m">1</span><span class="p">]]</span><span class="w">
</span></code></pre></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 2 × 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)     42.7     0.465      91.9 0       
## 2 netTRUE        -11.8     0.657     -18.0 1.04e-66
</code></pre></div></div><p>Now we have a distribution of estimates:</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ipw_results</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="c1"># remove original data set results</span><span class="w">
  </span><span class="n">filter</span><span class="p">(</span><span class="n">id</span><span class="w"> </span><span class="o">!=</span><span class="w"> </span><span class="s2">"Apparent"</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w"> 
  </span><span class="n">mutate</span><span class="p">(</span><span class="w">
    </span><span class="n">estimate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">map_dbl</span><span class="p">(</span><span class="w">
      </span><span class="n">boot_fits</span><span class="p">,</span><span class="w">
      </span><span class="c1"># pull the `estimate` for `netTRUE` for each fit</span><span class="w">
      </span><span class="err">\</span><span class="p">(</span><span class="n">.fit</span><span class="p">)</span><span class="w"> </span><span class="n">.fit</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
        </span><span class="n">filter</span><span class="p">(</span><span class="n">term</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">"netTRUE"</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
        </span><span class="n">pull</span><span class="p">(</span><span class="n">estimate</span><span class="p">)</span><span class="w">
    </span><span class="p">)</span><span class="w">
  </span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">estimate</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_histogram</span><span class="p">(</span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"#D55E00FF"</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"white"</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.8</span><span class="p">)</span><span class="w">
</span></code></pre></div></div><div class="figure"> <img src="../pages/causal_inference_whole_game_files/figure-gfm/fig-bootstrap-estimates-net-data-1.png" alt="&quot;A histogram of 1,000 bootstrapped estimates of the effect of net use on malaria risk. The spread of these estimates accounts for the dependency and uncertainty in the use of IPW weights.&quot;" /><p class="caption"> <span id="fig:fig-bootstrap-estimates-net-data"></span>Figure 1.8: “A histogram of 1,000 bootstrapped estimates of the effect of net use on malaria risk. The spread of these estimates accounts for the dependency and uncertainty in the use of IPW weights.”</p></div><p>Figure figure <a href="#fig:fig-bootstrap-estimates-net-data">1.8</a> gives a sense of the variation in <code class="language-plaintext highlighter-rouge">estimate</code>, but let’s calculate 95% confidence intervals from the bootstrapped distribution using rsample’s <code class="language-plaintext highlighter-rouge">int_t()</code> :</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">boot_estimate</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ipw_results</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="c1"># calculate T-statistic-based CIs</span><span class="w">
  </span><span class="n">int_t</span><span class="p">(</span><span class="n">boot_fits</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">filter</span><span class="p">(</span><span class="n">term</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">"netTRUE"</span><span class="p">)</span><span class="w">

</span><span class="n">boot_estimate</span><span class="w">
</span></code></pre></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 1 × 6
##   term    .lower .estimate .upper .alpha .method  
##   &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    
## 1 netTRUE  -13.4     -12.5  -11.7   0.05 student-t
</code></pre></div></div><p>Now we have a confounder-adjusted estimate with correct standard errors. The estimate of the effect of <em>all</em> households using bed nets versus <em>no</em> households using bed nets on malaria risk is -12.5 (95% CI -13.4, -11.7). Bed nets do indeed seem to reduce malaria risk in this study.</p><h2 id="15-conduct-sensitivity-analysis-on-the-effect-estimate"> <a href="#15-conduct-sensitivity-analysis-on-the-effect-estimate" class="anchor-heading" aria-labelledby="15-conduct-sensitivity-analysis-on-the-effect-estimate"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 1.5 Conduct sensitivity analysis on the effect estimate</h2><p>We’ve laid out a roadmap for taking observational data, thinking critically about the causal question we want to ask, identifying the assumptions we need to get there, then applying those assumptions to a statistical model. Getting the correct answer to the causal question relies on getting our assumptions more or less right. But what if we’re more on the less correct side?</p><p>Spoiler alert: the answer we just calculated is <em>wrong</em>. After all that effort!</p><p>When conducting a causal analysis, it’s a good idea to use sensitivity analyses to test your assumptions. There are many potential sources of bias in any study and many sensitivity analyses to go along with them (@sec-sensitivity); here, we’ll focus on the assumption of no confounding.</p><p>Let’s start with a broad sensitivity analysis; then, we’ll ask questions about specific unmeasured confounders. When we have less information about unmeasured confounders, we can use tipping point analysis to ask how much confounding it would take to tip my estimate to the null. In other words, what would the strength of the unmeasured confounder have to be to explain our results away? The tipr package is a toolkit for conducting sensitivity analyses. Let’s examine the tipping point for an unknown, normally-distributed confounder. The <code class="language-plaintext highlighter-rouge">tip_coef()</code> function takes an estimate (a beta coefficient from a regression model, or the upper or lower bound of the coefficient). It further requires either the 1) scaled differences in means of the confounder between exposure groups or 2) effect of the confounder on the outcome. For the estimate, we’ll use <code class="language-plaintext highlighter-rouge">conf.high</code>, which is closer to 0 (the null), and ask: how much would the confounder have to affect malaria risk to have an unbiased upper confidence interval of 0? We’ll use tipr to calculate this answer for 5 scenarios, where the mean difference in the confounder between exposure groups is 1, 2, 3, 4, or 5.</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="n">tipr</span><span class="p">)</span><span class="w">
</span><span class="n">tipping_points</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">tip_coef</span><span class="p">(</span><span class="n">boot_estimate</span><span class="o">$</span><span class="n">.upper</span><span class="p">,</span><span class="w"> </span><span class="n">exposure_confounder_effect</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1</span><span class="o">:</span><span class="m">5</span><span class="p">)</span><span class="w">

</span><span class="n">tipping_points</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">ggplot</span><span class="p">(</span><span class="n">aes</span><span class="p">(</span><span class="n">confounder_outcome_effect</span><span class="p">,</span><span class="w"> </span><span class="n">exposure_confounder_effect</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_line</span><span class="p">(</span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"#009E73"</span><span class="p">,</span><span class="w"> </span><span class="n">linewidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1.1</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">(</span><span class="n">fill</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"#009E73"</span><span class="p">,</span><span class="w"> </span><span class="n">color</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"white"</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">2.5</span><span class="p">,</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">21</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="w">
    </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Confounder-Outcome Effect"</span><span class="p">,</span><span class="w">
    </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Scaled mean differences in\n confounder between exposure groups"</span><span class="w">
  </span><span class="p">)</span><span class="w">
</span></code></pre></div></div><div class="figure"> <img src="../pages/causal_inference_whole_game_files/figure-gfm/fig-tip-coef-net-1.png" alt="A tipping point analysis under several confounding scenarios where the unmeasured confounder is a normally-distributed continuous variable. The line represents the strength of confounding necessary to tip the upper confidence interval of the causal effect estimate to 0. The x-axis represents the coefficient of the confounder-outcome relationship adjusted for the exposure and the set of measured confounders. The y-axis represents the scaled mean difference of the confounder between exposure groups." /><p class="caption"> <span id="fig:fig-tip-coef-net"></span>Figure 1.9: A tipping point analysis under several confounding scenarios where the unmeasured confounder is a normally-distributed continuous variable. The line represents the strength of confounding necessary to tip the upper confidence interval of the causal effect estimate to 0. The x-axis represents the coefficient of the confounder-outcome relationship adjusted for the exposure and the set of measured confounders. The y-axis represents the scaled mean difference of the confounder between exposure groups.</p></div><p>If we had an unmeasured confounder where the standardized mean difference between exposure groups was 1, the confounder would need to decrease malaria risk by about -11.7. That’s pretty strong relative to other effects, but it may be feasible if we have an idea of something we might have missed. Conversely, suppose the relationship between net use and the unmeasured confounder is very strong, with a mean scaled difference of 5. In that case, the confounder-malaria relationship only needs to be -2.3. Now we have to consider: which of these scenarios are plausible given our domain knowledge and the effects we see in this analysis?</p><p>Now let’s consider a much more specific sensitivity analysis. Some ethnic groups, such as the Fulani, have a genetic resistance to malaria [@arama2015]. Let’s say that in our simulated data, an unnamed ethnic group in the unnamed country shares this genetic resistance to malaria. For historical reasons, bed net use in this group is also very high. We don’t have this variable in <code class="language-plaintext highlighter-rouge">net_data</code>, but let’s say we know from the literature that in this sample, we can estimate at:</p><ol><li>People with this genetic resistance have, on average, a lower malaria risk by about 10.<li>About 26% of people who use nets in our study have this genetic resistance.<li>About 5% of people who don’t use nets have this genetic resistance.</ol><p>With this amount of information, we can use tipr to adjust the estimates we calculated for the unmeasured confounder. We’ll use <code class="language-plaintext highlighter-rouge">adjust_coef_with_binary()</code> to calculate the adjusted estimates.</p><div class="language-r highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">adjusted_estimates</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">boot_estimate</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">select</span><span class="p">(</span><span class="n">.estimate</span><span class="p">,</span><span class="w"> </span><span class="n">.lower</span><span class="p">,</span><span class="w"> </span><span class="n">.upper</span><span class="p">)</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">unlist</span><span class="p">()</span><span class="w"> </span><span class="o">|&gt;</span><span class="w">
  </span><span class="n">adjust_coef_with_binary</span><span class="p">(</span><span class="w">
    </span><span class="n">exposed_confounder_prev</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.26</span><span class="p">,</span><span class="w">
    </span><span class="n">unexposed_confounder_prev</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.05</span><span class="p">,</span><span class="w">
    </span><span class="n">confounder_outcome_effect</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">-10</span><span class="w">
  </span><span class="p">)</span><span class="w">

</span><span class="n">adjusted_estimates</span><span class="w">
</span></code></pre></div></div><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 3 × 4
##   effect_adjusted effect_observed
##             &lt;dbl&gt;           &lt;dbl&gt;
## 1          -10.4            -12.5
## 2          -11.3            -13.4
## 3           -9.63           -11.7
## # ℹ 2 more variables:
## #   exposure_confounder_effect &lt;dbl&gt;,
## #   confounder_outcome_effect &lt;dbl&gt;
</code></pre></div></div><p>The adjusted estimate for a situation where genetic resistance to malaria is a confounder is -10.4 (95% CI -11.3, -9.6).</p><p>In fact, these data were simulated with just such a confounder. The true effect of net use on malaria is about -10, and the true DAG that generated these data is:</p><div class="figure"> <img src="../pages/causal_inference_whole_game_files/figure-gfm/fig-net-data-true-dag-1.png" alt="The true causal diagram for `net_data`. This DAG is identical to the one we proposed with one addition: genetic resistance to malaria causally reduces the risk of malaria and impacts net use. It's thus a confounder and a part of the minimal adjustment set required to get an unbiased effect estimate. In otherwords, by not including it, we've calculated the wrong effect." /><p class="caption"> <span id="fig:fig-net-data-true-dag"></span>Figure 1.10: The true causal diagram for `net_data`. This DAG is identical to the one we proposed with one addition: genetic resistance to malaria causally reduces the risk of malaria and impacts net use. It’s thus a confounder and a part of the minimal adjustment set required to get an unbiased effect estimate. In otherwords, by not including it, we’ve calculated the wrong effect.</p></div><p>The unmeasured confounder in figure <a href="#fig:fig-net-data-true-dag">1.10</a> is available in the dataset <code class="language-plaintext highlighter-rouge">net_data_full</code> as <code class="language-plaintext highlighter-rouge">genetic_resistance</code>. If we recalculate the IPW estimate of the average treatment effect of nets on malaria risk, we get -10.3 (95% CI -11.2, -9.3), much closer to the actual answer of -10.</p><p>What do you think? Is this estimate reliable? Did we do a good job addressing the assumptions we need to make for a causal effect, mainly that there is no confounding? How might you criticize this model, and what would you do differently? Ok, we know that -10 is the correct answer because the data are simulated, but in practice, we can never be sure, so we need to continue probing our assumptions until we’re confident they are robust. We’ll explore these techniques and others in @sec-sensitivity.</p><p>To calculate this effect, we:</p><ol><li>Specified a causal question (for the average treatment effect)<li>Drew our assumptions using a causal diagram (using DAGs)<li>Modeled our assumptions (using propensity score weighting)<li>Diagnosed our models (by checking confounder balance after weighting)<li>Estimated the causal effect (using inverse probability weighting)<li>Conducted sensitivity analysis on the effect estimate (using tipping point analysis)</ol><p>We can dive more deeply into propensity score techniques, explore other methods for estimating causal effects, and, most importantly, make sure that the assumptions we’re making are reasonable, even if we’ll never know for sure.</p><hr><footer><div class="d-flex mt-2"></div></footer></div></div><div class="search-overlay"></div></div>
