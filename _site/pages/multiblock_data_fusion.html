<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="manifest" href="/site.webmanifest"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#edbe7a"><link rel="shortcut icon" href="/favicon.ico"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/browserconfig.xml"><meta name="theme-color" content="#ffffff"><title>Multiblock data fusion | Dev docs</title><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="Multiblock data fusion" /><meta property="og:locale" content="en_US" /><meta name="description" content="Dev docs made with Jeykll using the Just the Docs theme." /><meta property="og:description" content="Dev docs made with Jeykll using the Just the Docs theme." /><link rel="canonical" href="http://localhost:4000/pages/multiblock_data_fusion.html" /><meta property="og:url" content="http://localhost:4000/pages/multiblock_data_fusion.html" /><meta property="og:site_name" content="Dev docs" /><meta property="og:type" content="website" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Multiblock data fusion" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"Dev docs made with Jeykll using the Just the Docs theme.","headline":"Multiblock data fusion","url":"http://localhost:4000/pages/multiblock_data_fusion.html"}</script> <script type="text/javascript" defer src="/assets/js/mathjax-script-type.js"> </script> <script type="text/javascript" id="MathJax-script" defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"> </script><body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"><title id="svg-external-link-title">(external link)</title><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-copy" viewBox="0 0 16 16"><title>Copy</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"><title>Copied</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"><path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg><div class="side-bar"><div class="site-header"> <a href="/" class="site-title lh-tight"> Dev docs </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a></div><nav aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a><li class="nav-list-item"><a href="/pages/bam2fastq.html" class="nav-list-link">BWA</a><li class="nav-list-item"><a href="/pages/bayesian_example1.html" class="nav-list-link">Bayes 1 probability in placenta previa</a><li class="nav-list-item"><a href="/pages/bayesian_example2.html" class="nav-list-link">Bayesian 2 probability in placenta previa</a><li class="nav-list-item"><a href="/pages/bayesian_genetic_carrier.html" class="nav-list-link">Bayesian discrete probability example in genetics</a><li class="nav-list-item"><a href="/pages/bayesian_mcmc_samplers.html" class="nav-list-link">Bayes MCMC samplers</a><li class="nav-list-item"><a href="/pages/bayesian_multiparameter_bioassay.html" class="nav-list-link">Bayes multiparameter bioassay demo</a><li class="nav-list-item"><a href="/pages/bayesian_multiparameter_models.html" class="nav-list-link">Bayes multiparameter models</a><li class="nav-list-item"><a href="/pages/benchmark_pipelines.html" class="nav-list-link">Benchmarking pipeline output</a><li class="nav-list-item"><a href="/pages/bevimed.html" class="nav-list-link">BeviMed</a><li class="nav-list-item"><a href="/pages/biomedit.html" class="nav-list-link">BioMedIT</a><li class="nav-list-item"><a href="/pages/bookmarks.html" class="nav-list-link">Bookmarks</a><li class="nav-list-item"><a href="/pages/bwa.html" class="nav-list-link">BWA</a><li class="nav-list-item"><a href="/pages/causal_inference_stats.html" class="nav-list-link">Causal inference stats</a><li class="nav-list-item"><a href="/pages/causal_inference_whole_game.html" class="nav-list-link">Causal inference mosquito nets</a><li class="nav-list-item"><a href="/pages/data_concepts.html" class="nav-list-link">Data concepts</a><li class="nav-list-item"><a href="/pages/data_stream.html" class="nav-list-link">Data stream</a><li class="nav-list-item"><a href="#" class="nav-list-expander" aria-label="toggle links in Design documents category"> <svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg> </a><a href="/pages/design_doc.html" class="nav-list-link">Design documents</a><ul class="nav-list"><li class="nav-list-item "><a href="/pages/design_PCA_SNV_INDEL_V1.html" class="nav-list-link">Design PCA SNV INDEL v1</a><li class="nav-list-item "><a href="/pages/design_dna_snvindel_v1.html" class="nav-list-link">Design DNA SNV INDEL v1</a><li class="nav-list-item "><a href="/pages/design_dna_snvindel_v1_release.html" class="nav-list-link">Design release DNA SNV INDEL v1</a><li class="nav-list-item "><a href="/pages/design_dna_snvindel_v2_release.html" class="nav-list-link">Design release DNA SNV INDEL v2</a><li class="nav-list-item "><a href="/pages/design_qv_snvindel_v1.html" class="nav-list-link">Design QV SNV INDEL v1</a><li class="nav-list-item "><a href="/pages/design_statistical_genomics_v1.html" class="nav-list-link">Design statistical genomics v1</a></ul><li class="nav-list-item"><a href="/pages/dna_annotation.html" class="nav-list-link">DNA annotation</a><li class="nav-list-item"><a href="/pages/dna_interpretation.html" class="nav-list-link">DNA interpretation</a><li class="nav-list-item"><a href="/pages/dna_qc.html" class="nav-list-link">DNA QC</a><li class="nav-list-item"><a href="/pages/docker_singularity.html" class="nav-list-link">Docker with singularity</a><li class="nav-list-item"><a href="/pages/fastp.html" class="nav-list-link">FASTP</a><li class="nav-list-item"><a href="/pages/fastq.html" class="nav-list-link">FASTQ format data</a><li class="nav-list-item"><a href="/pages/filter_vcf_bcftools.html" class="nav-list-link">Filter VCF with bcftools</a><li class="nav-list-item"><a href="/pages/financial_management.html" class="nav-list-link">Financial management</a><li class="nav-list-item"><a href="/pages/guru.html" class="nav-list-link">Guru variant interpretation</a><li class="nav-list-item"><a href="/pages/gwas.html" class="nav-list-link">GWAS analysis</a><li class="nav-list-item"><a href="/pages/hpc.html" class="nav-list-link">HPC infrastructure</a><li class="nav-list-item"><a href="/pages/inf_causal_metab_sem.html" class="nav-list-link">Inference of causal metabolite networks</a><li class="nav-list-item"><a href="/pages/layout.html" class="nav-list-link">Layout</a><li class="nav-list-item"><a href="/pages/mathjax.html" class="nav-list-link">MathJax config</a><li class="nav-list-item"><a href="/pages/mbdf_models.html" class="nav-list-link">MBDF models</a><li class="nav-list-item"><a href="/pages/mbdf_supervised.html" class="nav-list-link">MBDF supervised</a><li class="nav-list-item"><a href="/pages/mbdf_unsupervised.html" class="nav-list-link">MBDF unsupervised</a><li class="nav-list-item"><a href="/pages/metadata.html" class="nav-list-link">WGS metadata</a><li class="nav-list-item"><a href="/pages/metrics_bcftoolscounts.html" class="nav-list-link">Metrics Bcftools counts</a><li class="nav-list-item"><a href="/pages/metrics_bcftoolsstats.html" class="nav-list-link">Metrics Bcftools stats</a><li class="nav-list-item"><a href="/pages/metrics_collectwgsmetrics.html" class="nav-list-link">Metrics CollectWgsMetrics</a><li class="nav-list-item active"><a href="/pages/multiblock_data_fusion.html" class="nav-list-link active">Multiblock data fusion</a><li class="nav-list-item"><a href="/pages/panels_disease.html" class="nav-list-link">Panels disease gene</a><li class="nav-list-item"><a href="/pages/pca_biplot_1kg.html" class="nav-list-link">PCA biplot 1000genomes</a><li class="nav-list-item"><a href="/pages/pca_features.html" class="nav-list-link">PCA features</a><li class="nav-list-item"><a href="/pages/platform_updates.html" class="nav-list-link">Platform updates</a><li class="nav-list-item"><a href="/pages/precision_med.html" class="nav-list-link">Precision Medicine Unit (PMU)</a><li class="nav-list-item"><a href="/pages/present/presentations.html" class="nav-list-link">Presentations</a><li class="nav-list-item"><a href="/pages/read_group.html" class="nav-list-link">Read group</a><li class="nav-list-item"><a href="/pages/ref.html" class="nav-list-link">Reference genome</a><li class="nav-list-item"><a href="/pages/rl_finte_mdp.html" class="nav-list-link">RL finite MDP</a><li class="nav-list-item"><a href="/pages/slurm_manager.html" class="nav-list-link">SLURM monitoring</a><li class="nav-list-item"><a href="/pages/slurm_sbatch.html" class="nav-list-link">SLURM sbatch headers</a><li class="nav-list-item"><a href="/pages/stats_altman_bland_analysis_of_methods.html" class="nav-list-link">Stats Analysis of methods</a><li class="nav-list-item"><a href="/pages/stats_altman_bland_ci_from_p.html" class="nav-list-link">Stats CI from P</a><li class="nav-list-item"><a href="/pages/stats_altman_bland_correlation.html" class="nav-list-link">Stats Correlation, regression and repeated data</a><li class="nav-list-item"><a href="/pages/stats_altman_bland_odds_ratios.html" class="nav-list-link">Stats Odds ratios, SE & CI</a><li class="nav-list-item"><a href="/pages/stats_altman_bland_roc_curve.html" class="nav-list-link">Stats Receiver operating characteristic plots</a><li class="nav-list-item"><a href="/pages/stats_altman_bland_sensitivity_specificity.html" class="nav-list-link">Stats Sensitivity and specificity</a><li class="nav-list-item"><a href="/pages/storage_architecture_plan.html" class="nav-list-link">Storage architecture plan</a><li class="nav-list-item"><a href="/pages/storage_estimates.html" class="nav-list-link">Storage estimates</a><li class="nav-list-item"><a href="/pages/storage_use_sync_and_versioning.html" class="nav-list-link">Storage, usage, and Git practices</a><li class="nav-list-item"><a href="/pages/style.html" class="nav-list-link">Style page guide</a><li class="nav-list-item"><a href="/pages/style_writing.html" class="nav-list-link">Style writing guide</a><li class="nav-list-item"><a href="/pages/sv.html" class="nav-list-link">Structural variation detection</a><li class="nav-list-item"><a href="/pages/synth_data.html" class="nav-list-link">Synthetic data</a><li class="nav-list-item"><a href="/pages/variables.html" class="nav-list-link">Variables</a><li class="nav-list-item"><a href="/pages/Phoenix_Sepsis_Score_logic.html" class="nav-list-link">Sepsis score: Phoenix</a><li class="nav-list-item"><a href="/pages/vcf.html" class="nav-list-link">VCF - Variant Call Format</a><li class="nav-list-item"><a href="/pages/vcf_gvcf.html" class="nav-list-link">VCF and gVCF</a><li class="nav-list-item"><a href="/pages/virtual_panels.html" class="nav-list-link">Virtual gene panels</a><li class="nav-list-item"><a href="/pages/vsat.html" class="nav-list-link">VSAT with SKAT</a><li class="nav-list-item"><a href="/pages/vsat_setID.html" class="nav-list-link">SetID for VSAT</a><li class="nav-list-item"><a href="/pages/variant_concept.html" class="nav-list-link">Variant to RDF concept</a><li class="nav-list-item"><a href="/pages/acat.html" class="nav-list-link">ACAT</a><li class="nav-list-item"><a href="/pages/acmg_criteria_table_main.html" class="nav-list-link">ACMG criteria</a><li class="nav-list-item"><a href="/pages/aggregate_multiplex.html" class="nav-list-link">Aggregate multiplexed data</a><li class="nav-list-item"><a href="/pages/annotation_table.html" class="nav-list-link">Annotation table</a><li class="nav-list-item"><a href="/pages/documentation_log.html" class="nav-list-link">Documentation log</a></ul></nav><footer class="site-footer"> Maintained by <a href="https://github.com/DylanLawless">Dylan Lawless</a> for <a href="https://switzerlandomics.ch">SwitzerlandOmics.ch</a>.</footer></div><div class="main" id="top"><div id="main-header" class="main-header"><div class="search"><div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Dev docs" aria-label="Search Dev docs" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label></div><div id="search-results" class="search-results"></div></div><nav aria-label="Auxiliary" class="aux-nav"><ul class="aux-nav-list"><li class="aux-nav-list-item"> <a href="https://github.com/docs-switzerlandomics.github.io" class="site-button" > Github </a><li class="aux-nav-list-item"> <a href="https://switzerlandomics.ch" class="site-button" > SwitzerlandOmics.ch </a></ul></nav></div><div id="main-content-wrap" class="main-content-wrap"><div id="main-content" class="main-content" role="main"><h1 id="multiblock-data-fusion-in-statistics-and-machine-learning"> <a href="#multiblock-data-fusion-in-statistics-and-machine-learning" class="anchor-heading" aria-labelledby="multiblock-data-fusion-in-statistics-and-machine-learning"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Multiblock Data Fusion in Statistics and Machine Learning</h1><p>Last update: 20250108</p><details open="" class="no_toc"> <summary class="text-delta"> Table of contents </summary><ul id="markdown-toc"><li><a href="#multiblock-data-fusion-in-statistics-and-machine-learning" id="markdown-toc-multiblock-data-fusion-in-statistics-and-machine-learning">Multiblock Data Fusion in Statistics and Machine Learning</a><ul><li><a href="#unsupervised-methods-in-selected-methods-for-unsupervised-and-supervised-topologies-chapter-5" id="markdown-toc-unsupervised-methods-in-selected-methods-for-unsupervised-and-supervised-topologies-chapter-5">Unsupervised Methods in Selected Methods for Unsupervised and Supervised Topologies (Chapter 5)</a><ul><li><a href="#shared-variable-mode" id="markdown-toc-shared-variable-mode">Shared Variable Mode</a><li><a href="#shared-sample-mode" id="markdown-toc-shared-sample-mode">Shared Sample Mode</a><li><a href="#advanced-topics" id="markdown-toc-advanced-topics">Advanced Topics</a><li><a href="#framework-and-methodological-considerations" id="markdown-toc-framework-and-methodological-considerations">Framework and Methodological Considerations</a><li><a href="#concluding-thoughts" id="markdown-toc-concluding-thoughts">Concluding Thoughts</a></ul><li><a href="#alternative-unsupervised-methods-chapter-9" id="markdown-toc-alternative-unsupervised-methods-chapter-9">Alternative Unsupervised Methods (chapter 9)</a><ul><li><a href="#9i-general-introduction" id="markdown-toc-9i-general-introduction">9.i General Introduction</a><li><a href="#9ii-relationship-to-the-general-framework" id="markdown-toc-9ii-relationship-to-the-general-framework">9.ii Relationship to the General Framework</a><li><a href="#91-shared-variable-mode" id="markdown-toc-91-shared-variable-mode">9.1 Shared Variable Mode</a><ul><li><a href="#generalised-svd" id="markdown-toc-generalised-svd">Generalised SVD</a></ul></ul><li><a href="#92-shared-sample-mode" id="markdown-toc-92-shared-sample-mode">9.2 Shared Sample Mode</a><ul><li><a href="#921-only-common-variation" id="markdown-toc-921-only-common-variation">9.2.1 Only Common Variation</a><ul><li><a href="#9211-diablo" id="markdown-toc-9211-diablo">9.2.1.1 DIABLO</a><li><a href="#9212-generalised-coupled-tensor-factorisation" id="markdown-toc-9212-generalised-coupled-tensor-factorisation">9.2.1.2 Generalised Coupled Tensor Factorisation</a><li><a href="#9213-representation-matrices" id="markdown-toc-9213-representation-matrices">9.2.1.3 Representation Matrices</a><li><a href="#9214-extended-pca" id="markdown-toc-9214-extended-pca">9.2.1.4 Extended PCA</a></ul><li><a href="#922-common-local-and-distinct-variation" id="markdown-toc-922-common-local-and-distinct-variation">9.2.2 Common, Local, and Distinct Variation</a><ul><li><a href="#9221-generalised-svd" id="markdown-toc-9221-generalised-svd">9.2.2.1 Generalised SVD</a><li><a href="#9222-structural-learning-and-integrative-decomposition" id="markdown-toc-9222-structural-learning-and-integrative-decomposition">9.2.2.2 Structural Learning and Integrative Decomposition</a><li><a href="#9223-bayesian-inter-battery-factor-analysis" id="markdown-toc-9223-bayesian-inter-battery-factor-analysis">9.2.2.3 Bayesian Inter-battery Factor Analysis</a><li><a href="#9224-group-factor-analysis" id="markdown-toc-9224-group-factor-analysis">9.2.2.4 Group Factor Analysis</a><li><a href="#9225-onpls" id="markdown-toc-9225-onpls">9.2.2.5 OnPLS</a><li><a href="#9226-generalised-association-study" id="markdown-toc-9226-generalised-association-study">9.2.2.6 Generalised Association Study</a><li><a href="#9227-multi-omics-factor-analysis" id="markdown-toc-9227-multi-omics-factor-analysis">9.2.2.7 Multi-Omics Factor Analysis</a></ul><li><a href="#93-two-shared-modes-and-only-common-variation" id="markdown-toc-93-two-shared-modes-and-only-common-variation">9.3 Two Shared Modes and Only Common Variation</a><ul><li><a href="#931-generalised-procrustes-analysis-gpa" id="markdown-toc-931-generalised-procrustes-analysis-gpa">9.3.1 Generalised Procrustes Analysis (GPA)</a><li><a href="#932-three-way-methods" id="markdown-toc-932-three-way-methods">9.3.2 Three-way Methods</a></ul><li><a href="#94-conclusions-and-recommendations" id="markdown-toc-94-conclusions-and-recommendations">9.4 Conclusions and Recommendations</a><li><a href="#941-open-issues" id="markdown-toc-941-open-issues">9.4.1 Open Issues</a></ul><li><a href="#decision-trees" id="markdown-toc-decision-trees">Decision trees</a><li><a href="#method-list" id="markdown-toc-method-list">Method list</a></ul></ul></details><hr /><p class="warning">This text is largely summarised directly from the following source. Please see the original for details and credit.</p><p>This is a review of selected topics from the textbook: “Multiblock Data Fusion in Statistics and Machine Learning” 2022. Age K. Smilde, Tormod Næs, Kristian Hovde Liland. <a href="https://onlinelibrary.wiley.com/doi/book/10.1002/9781119600978">https://onlinelibrary.wiley.com/doi/book/10.1002/9781119600978</a></p><h2 id="unsupervised-methods-in-selected-methods-for-unsupervised-and-supervised-topologies-chapter-5"> <a href="#unsupervised-methods-in-selected-methods-for-unsupervised-and-supervised-topologies-chapter-5" class="anchor-heading" aria-labelledby="unsupervised-methods-in-selected-methods-for-unsupervised-and-supervised-topologies-chapter-5"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Unsupervised Methods in Selected Methods for Unsupervised and Supervised Topologies (Chapter 5)</h2><p>Chapter 5 delves into various unsupervised methods used in multiblock data analysis, focusing primarily on shared variable and shared sample modes while also exploring different variations such as only common variation and common, local, and distinct variations.</p><h3 id="shared-variable-mode"> <a href="#shared-variable-mode" class="anchor-heading" aria-labelledby="shared-variable-mode"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Shared Variable Mode</h3><p>The chapter begins by examining methods in the shared variable mode, with a specific focus on isolating only common variations such as Simultaneous Component Analysis (SCA), which integrates data from multiple sources to find common patterns. It also addresses more complex structures that include both common and distinct variations, employing methods like Distinct and Common Components Analysis and Multivariate Curve Resolution to dissect the unique and shared signals within the data.</p><h3 id="shared-sample-mode"> <a href="#shared-sample-mode" class="anchor-heading" aria-labelledby="shared-sample-mode"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Shared Sample Mode</h3><p>In the shared sample mode, the discussion shifts towards methods designed to handle data structures where samples are shared across different datasets but the variables may differ. Techniques like SUM-PCA and Multiple Factor Analysis provide tools for extracting common information across these shared samples. The chapter further explores the integration of these methods with statistical techniques like Generalised Canonical Analysis and Regularised Generalised Canonical Correlation Analysis, enhancing their ability to deal with various data complexities including high-dimensionality and under-determined systems. Exponential Family SCA and Optimal-scaling are discussed for their ability to adapt the component analysis to different scales and data distributions.</p><h3 id="advanced-topics"> <a href="#advanced-topics" class="anchor-heading" aria-labelledby="advanced-topics"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Advanced Topics</h3><p>The latter sections of the chapter address more advanced topics, such as Joint and Individual Variation Explained (JIVE) for parsing out distinct and shared information across multiple datasets, and Advanced Coupled Matrix and Tensor Factorisation, which extend these concepts into higher-dimensional data. Penalised-ESCA and further Multivariate Curve Resolution approaches are introduced for dealing with extremely heterogeneous data.</p><h3 id="framework-and-methodological-considerations"> <a href="#framework-and-methodological-considerations" class="anchor-heading" aria-labelledby="framework-and-methodological-considerations"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Framework and Methodological Considerations</h3><p>A generic framework for simultaneous unsupervised methods is outlined, providing a structured approach to applying these diverse methodologies across different types of multiblock data scenarios. This framework helps in identifying the appropriate methodological adjustments needed for specific data characteristics and analysis goals.</p><h3 id="concluding-thoughts"> <a href="#concluding-thoughts" class="anchor-heading" aria-labelledby="concluding-thoughts"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Concluding Thoughts</h3><p>The chapter concludes with a synthesis of the discussed methods, offering recommendations based on the complexities and specific requirements of various data analysis scenarios. Open issues in the field are highlighted, pointing to areas where further research and development are needed to advance the capabilities of unsupervised multiblock data analysis.</p><h2 id="alternative-unsupervised-methods-chapter-9"> <a href="#alternative-unsupervised-methods-chapter-9" class="anchor-heading" aria-labelledby="alternative-unsupervised-methods-chapter-9"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Alternative Unsupervised Methods (chapter 9)</h2><h3 id="9i-general-introduction"> <a href="#9i-general-introduction" class="anchor-heading" aria-labelledby="9i-general-introduction"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.i General Introduction</h3><p>This chapter explores some unsupervised methods that are less commonly used than those highlighted in Chapter 5. This does not necessarily indicate that they are less useful, but rather that some are relatively new and their full potential is still being evaluated. We will cover methods that focus on identifying common variation as well as those that can differentiate between common, local, and distinct variations. The methods discussed will apply to data situations with a shared variable mode, a shared sample mode, and scenarios where both modes are shared. We will examine approaches suitable for both homogeneous and heterogeneous data fusion. Throughout this chapter, we will assume that data blocks are column-centred unless stated otherwise, and the default norm used for vectors and matrices will be the Frobenius norm.</p><h3 id="9ii-relationship-to-the-general-framework"> <a href="#9ii-relationship-to-the-general-framework" class="anchor-heading" aria-labelledby="9ii-relationship-to-the-general-framework"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.ii Relationship to the General Framework</h3><p>This section provides a brief overview of the unsupervised methods discussed in this chapter as outlined in Table 10.1. The table illustrates a diverse range of methods based on different foundational principles. Most methods operate simultaneously and are model-based, including those based on factor analysis models that incorporate penalties (such as BIBFA, GFA, MOFA, and GAS) and are capable of handling heterogeneous data. The representation method (RM) provides a unique approach through three-way models of specially constructed data representations. Other methods discussed include generalizations of SVD (GSVD) and methods based on copulas (XPCA). This diversity showcases the rich variety of data science approaches available to address similar problems across different fields.</p><h3 id="91-shared-variable-mode"> <a href="#91-shared-variable-mode" class="anchor-heading" aria-labelledby="91-shared-variable-mode"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.1 Shared Variable Mode</h3><p>In scenarios involving a shared variable mode, we explore methods that can distinguish between common and distinct components. One such method is the generalized singular value decomposition (GSVD), also known as quotient SVD (QSVD), which has been developed over the years (Van Loan, 1976; Paige and Saunders, 1981; De Moor and Zha, 1991). GSVD is an eigenvalue-based technique for separating common from distinct components in shared variable contexts.</p><h4 id="generalised-svd"> <a href="#generalised-svd" class="anchor-heading" aria-labelledby="generalised-svd"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Generalised SVD</h4><p>For two data blocks, the GSVD model is formulated as follows: \(X_1 = X̃_1 + E_1 = T_1 D_1 P^T + E_1\) \(X_2 = X̃_2 + E_2 = T_2 D_2 P^T + E_2\) Here, (X̃_m) represents the data filtered through an SCA model applied to the concatenated matrix ([X = [X_1^T|X_2^T]^T]). The matrices (T_m) are orthonormal (i.e., (T_m^T T_m = I)), and (P) is a full-rank matrix of common loadings, which are not necessarily orthonormal. The matrix (D_m) is diagonal, and the constraint (D_1 + D_2 = I) allows the generalised singular values to be categorized into three groups based on their significance in each block, which aids in distinguishing between common and distinct components.</p><p>The model structure is such that: \(X_1 = T_{11} D_{11} P_{t1} + T_{12} D_{12} P_{t2} + T_{13} D_{13} P_{t3} + E_1\) \(X_2 = T_{21} D_{21} P_{t1} + T_{22} D_{22} P_{t2} + T_{23} D_{23} P_{t3} + E_2\) The matrices (D_{11}) and (D_{22}) represent distinct components for (X_1) and (X_2), respectively, while (D_{13}) and (D_{23}) indicate the common components. Ideally, the matrices (D_{12}) and (D_{21}) should contain small values, indicating minimal ‘spill-over’ between the distinct and common components.</p><p>This method has been applied in various fields, including gene-expression analysis, and has been extended to handle more than two data blocks, allowing for the detection of common, local, and distinct components across multiple blocks. However, determining these components in the context of multiple blocks is complex and requires careful analysis.</p><h2 id="92-shared-sample-mode"> <a href="#92-shared-sample-mode" class="anchor-heading" aria-labelledby="92-shared-sample-mode"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.2 Shared Sample Mode</h2><h3 id="921-only-common-variation"> <a href="#921-only-common-variation" class="anchor-heading" aria-labelledby="921-only-common-variation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.2.1 Only Common Variation</h3><h4 id="9211-diablo"> <a href="#9211-diablo" class="anchor-heading" aria-labelledby="9211-diablo"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.2.1.1 DIABLO</h4><p>A method used in bioinformatics for multiblock data analysis is called Data Integration Analysis for Biomarker discovery using a Latent component method for Omics studies, DIABLO for short. This method relies strongly on the RGCCA method (see Section 5.2.1.4) and has been implemented in a sparse version (Singh et al., 2019). The model formulation is: \(\max \sum_{m,m'=1}^M c_{m,m'} \text{corr}(X_m w_m, X_{m'} w_{m'}) \text{ s.t. } \|w_m\|_2 = 1, \|w_{m'}\|_1 &lt; \lambda_{m'}\) where (c_{m,m’}) indicates connected blocks, components (t_m = X_m w_m) are calculated, (\lambda_m &gt; 0) are user-set penalties, ensuring ( |w_{m’}|<em>1 &lt; \lambda</em>{m’} ) as a lasso-type penalty. Deflation is performed by ( X_{m,\text{new}} = X_m - t_m w_{m’}^T ). This model, similar to RGCCA, uses deflation not trivial to apply (also see Section 2.8). An example of DIABLO is given in Elaboration 9.1, demonstrating a maximization of correlations across three data blocks, generalizing canonical correlation to multiple blocks.</p><h4 id="9212-generalised-coupled-tensor-factorisation"> <a href="#9212-generalised-coupled-tensor-factorisation" class="anchor-heading" aria-labelledby="9212-generalised-coupled-tensor-factorisation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.2.1.2 Generalised Coupled Tensor Factorisation</h4><p>Generalised coupled tensor factorisation (GCTF) (Yılmaz et al., 2011) extends coupled matrix tensor factorisation (CMTF) to heterogeneous data using exponential dispersion models (Jørgensen, 1992). It involves minimizing: \(\min \sum_{m=1}^M v_m d_m [X_m - X_m(\theta, \theta_m)]\) with (d_m) as a divergence measure, (\theta) and (\theta_m) as common and block-specific parameters, respectively, and (v_m) as weights. This method is applicable in a Bayesian framework for learning weights (Şimşekli et al., 2013), representing a generalization of GSCA and ESCA models (see Section 5.2.1.5).</p><h4 id="9213-representation-matrices"> <a href="#9213-representation-matrices" class="anchor-heading" aria-labelledby="9213-representation-matrices"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.2.1.3 Representation Matrices</h4><p>Representation matrices encode variables differently in multivariate analysis, useful for handling diverse data types and measurement scales. Originally termed quantification matrices, these matrices facilitate variable associations analysis. Representation matrices for ratio-, interval-, and ordinal-scaled variables transform variable measurements into forms suitable for generating familiar associations like Pearson and Spearman correlations using: \(q_{jk} = \frac{2 \text{tr}(S^T_j S_k)}{\text{tr}(S^T_j S_j) + \text{tr}(S^T_k S_k)}\) For nominal-scaled variables, square matrices based on indicator matrices are used, particularly effective for categorical data, giving rise to known correlation measures like T2 coefficient (Tschuprow, 1939).</p><h4 id="9214-extended-pca"> <a href="#9214-extended-pca" class="anchor-heading" aria-labelledby="9214-extended-pca"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.2.1.4 Extended PCA</h4><p>Extended PCA (XPCA) (Anderson-Bergman et al., 2018) employs copulas to handle J-dimensional distributions comprising diverse marginal distributions using a Gaussian copula for PCA. This method integrates empirical distributions estimated from heterogeneous data, offering potential applications in natural and life sciences.</p><h3 id="922-common-local-and-distinct-variation"> <a href="#922-common-local-and-distinct-variation" class="anchor-heading" aria-labelledby="922-common-local-and-distinct-variation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.2.2 Common, Local, and Distinct Variation</h3><p>For a shared sample mode, several methods exist to separate common, local, and distinct components, applicable to both homogeneous and heterogeneous data.</p><h4 id="9221-generalised-svd"> <a href="#9221-generalised-svd" class="anchor-heading" aria-labelledby="9221-generalised-svd"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.2.2.1 Generalised SVD</h4><p>Generalised SVD (GSVD) extends the approach used in shared variable modes to shared sample modes by focusing on consensus scores (T) rather than loadings. For two data blocks X1 (I × J1) and X2 (I × J2): \(X1 = \tilde{X}_1 + E1 = TD1P^T_1 + E1\) \(X2 = \tilde{X}_2 + E2 = TD2P^T_2 + E2\) where (\tilde{X}_m) are SCA-filtered data, T is a full-rank matrix, (P^T_m P_m = I), and (D_1 + D_2 = I). The elements of (D_m) categorize into distinct parts for X1 and X2, and a common part reflected in both X1 and X2 through consensus scores (T1, T2, T3) and respective loadings. An extension of GSVD for more than two data blocks exists (Ponnapalli et al., 2011) but integrating local components remains complex, discussed in Section 11.5.2.</p><h4 id="9222-structural-learning-and-integrative-decomposition"> <a href="#9222-structural-learning-and-integrative-decomposition" class="anchor-heading" aria-labelledby="9222-structural-learning-and-integrative-decomposition"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.2.2.2 Structural Learning and Integrative Decomposition</h4><p>Structural Learning and Integrative Decomposition (SLIDE) (Gaynanova and Li, 2019), similar to PESCA, imposes group penalties on loading matrices to discover the structure of common, local, and distinct components across data blocks. Starting with an SCA model: \(X1 = TP^T_1 + E1, X2 = TP^T_2 + E2, X3 = TP^T_3 + E3\) After fitting, loading matrices might show patterns such as: \(P1 = [xx00xx], P2 = [xxx000], P3 = [xxxx00]\) indicating components’ relevance across blocks: first two are common, third is local between blocks 2 and 3, and the last are distinct. SLIDE determines the structure of components through penalisation, allowing a re-fit with these identified structures. The method’s uniqueness relies on the same principles as JIVE (Section 5.2.2.1), with variations in group penalties proposed (Van Deun et al., 2011).</p><h4 id="9223-bayesian-inter-battery-factor-analysis"> <a href="#9223-bayesian-inter-battery-factor-analysis" class="anchor-heading" aria-labelledby="9223-bayesian-inter-battery-factor-analysis"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.2.2.3 Bayesian Inter-battery Factor Analysis</h4><p>Bayesian Inter-battery Factor Analysis (BIBFA) (Klami et al., 2013) builds on Tucker’s inter-battery factor analysis (1958) and its probabilistic counterpart (Browne, 1979). BIBFA separates the common and distinct parts of two data blocks: \(t \sim N(0, I), \quad t_m \sim N(0, I), \quad x_m \sim N(P_m C t + P_m D t_m, \Sigma_m)\) where (P_m) are loadings, (t, t_m) are scores with t representing consensus scores. BIBFA redefines this model in a Bayesian framework with structured priors to determine component numbers and structural models. Its applications include genomics and analytical chemistry (Acar et al., 2015), demonstrating its utility in decomposing complex data into meaningful components, though setting appropriate priors remains crucial for model performance.</p><p>These methods collectively address the challenges of multiblock data analysis by delineating shared and unique variance components across various data types, enhancing interpretability and applicative value in diverse scientific domains.</p><h4 id="9224-group-factor-analysis"> <a href="#9224-group-factor-analysis" class="anchor-heading" aria-labelledby="9224-group-factor-analysis"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.2.2.4 Group Factor Analysis</h4><p>Group Factor Analysis (GFA) is a machine learning method that extends Bayesian Inter-battery Factor Analysis (BIBFA). It begins with a factor analysis model: \(X = TP^T + E\) Assuming (X) is the concatenation of ([X_1 | \ldots | X_M]), the GFA model is expressed as: \([X_1 | \ldots | X_M] = T[P_1 | \ldots | P_M]^T + [E_1 | \ldots | E_M]\) This setup is similar to the SLIDE model but uses a fully stochastic model where the latent variables (T) are Gaussian distributed, an assumption significant for data with inherent structural relationships, such as experimental designs in the natural and life sciences. GFA allows for independent and normally distributed residuals with potentially differing variances across blocks. It applies Bayesian maximum-likelihood estimation with a group-wise ARD prior for identifying common, local, and distinct components. Reported applications include genomics and fMRI studies (Virtanen et al., 2012).</p><h4 id="9225-onpls"> <a href="#9225-onpls" class="anchor-heading" aria-labelledby="9225-onpls"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.2.2.5 OnPLS</h4><p>OnPLS, an extension of O2PLS, focuses on identifying common and distinct components across multiple data blocks. Initially developed for two data blocks with shared sample modes, the model for two blocks, (X_1) and (X_2), is structured as: \(X_1 = T_1C P_{t1C} + T_1D P_{t1D} + E_1 = X_1C + X_1D + E_1\) \(X_2 = T_2C P_{t2C} + T_2D P_{t2D} + E_2 = X_2C + X_2D + E_1\) Where (T_1DP_{t1D}) and (T_2DP_{t2D}) can be seen as distinct components, previously referred to as structural noise. OnPLS generalizes this structure for multiple blocks, effectively parsing data into components that are either shared, local to specific pairs of datasets, or unique to individual datasets. This model has been used in various omics and metabolomics studies, demonstrating its utility in complex data integration scenarios (Löfstedt and Trygg, 2011).</p><h4 id="9226-generalised-association-study"> <a href="#9226-generalised-association-study" class="anchor-heading" aria-labelledby="9226-generalised-association-study"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.2.2.6 Generalised Association Study</h4><p>The Generalised Association Study (GAS) integrates features from JIVE with extensions to handle heterogeneous data using exponential family distributions. The model posits: \(\Theta_1 = 1 \mu_{t1} + T C P_{t1C} + T_1D P_{t1D}\) \(\Theta_2 = 1 \mu_{t2} + T C P_{t2C} + T_2D P_{t2D}\) This model structure is similar to JIVE but includes additional constraints for identifiability and assumes pre-determined dimensionalities for matrices (T_C), (T_1D), and (T_2D). GAS estimates model parameters using a block-descent algorithm within a GLM framework, addressing the distinct challenges of handling data with different distributions (Li and Gaynanova, 2018).</p><h4 id="9227-multi-omics-factor-analysis"> <a href="#9227-multi-omics-factor-analysis" class="anchor-heading" aria-labelledby="9227-multi-omics-factor-analysis"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.2.2.7 Multi-Omics Factor Analysis</h4><p>Multi-omics Factor Analysis (MOFA) is a Bayesian model that extends BIBFA and GFA to accommodate heterogeneous data from multiple sources, such as different omics technologies. It employs: \(X_m = T P_{tm} + E_m; \quad m = 1, \ldots, M\) Where (T) includes all latent variables (common, local, distinct). MOFA uses ARD and spike-and-slab priors to enforce different sparsity levels across the factors, suitable for datasets with varying degrees of underlying structure and noise levels. Its complex Bayesian framework requires robust statistical knowledge for effective application. MOFA’s ability to learn the structure of loadings (P) from data distinguishes it from models requiring a priori structure specifications, like DISCO models (Argelaguet et al., 2018).</p><p>The example provided for MOFA and PESCA illustrates the practical applications of these models in understanding complex relationships in chronic lymphocytic leukaemia data, highlighting the flexibility and depth of insights achievable through advanced multiblock data analysis methods.</p><h3 id="93-two-shared-modes-and-only-common-variation"> <a href="#93-two-shared-modes-and-only-common-variation" class="anchor-heading" aria-labelledby="93-two-shared-modes-and-only-common-variation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.3 Two Shared Modes and Only Common Variation</h3><p>When datasets possess two shared modes, special analytical methods are required. This typically involves the same set of samples and variables measured across different occasions, demanding techniques that can address the complexities of repeated measurements. The nature of the data and the specific research questions posed dictate the choice of method.</p><h4 id="931-generalised-procrustes-analysis-gpa"> <a href="#931-generalised-procrustes-analysis-gpa" class="anchor-heading" aria-labelledby="931-generalised-procrustes-analysis-gpa"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.3.1 Generalised Procrustes Analysis (GPA)</h4><p>In contexts such as sensory analysis where different assessors evaluate the same products using the same sensory characteristics, there is a need to achieve consensus among assessors. Generalised Procrustes Analysis (GPA) is well-suited for this purpose. GPA aims to align the configurations of samples across multiple blocks of data (e.g., different assessors) as closely as possible in terms of translation, dilation, and rotation. Column-centring each data block handles translation, while optimal scaling factors and rotation matrices ((\lambda_m)s and (Q_m)s) are used to manage dilation and rotation, minimizing the Frobenius norm of the differences between each block and a consensus configuration (V). This consensus can then be analyzed further, typically with principal component analysis (PCA) to understand the variance and similarities across blocks. GPA’s versatility extends beyond sensory analysis to fields like genomics, indicating its broad applicability in multidisciplinary research.</p><h4 id="932-three-way-methods"> <a href="#932-three-way-methods" class="anchor-heading" aria-labelledby="932-three-way-methods"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.3.2 Three-way Methods</h4><p>For datasets that can be structured into three-dimensional arrays (three-way data), methods like PARAFAC (Parallel Factor Analysis) and Tucker3 models provide powerful tools for decomposition. These methods are particularly relevant for chemical data measured through techniques like excitation-emission fluorescence spectroscopy, where the goal is to estimate underlying chemical concentrations:</p><ul><li><p><strong>PARAFAC</strong>: Simplifies the analysis by decomposing a three-way array into three matrices corresponding to each mode, linked by a Khatri-Rao product. It assumes a simple structure where each component is linked to only one factor per mode, facilitating interpretation but potentially limiting flexibility.</p><li><p><strong>Tucker3</strong>: Offers a more general form of three-way decomposition, utilizing a core array that interacts with matrices corresponding to each mode. This method can adapt to more complex variations in data structures, accommodating different numbers of components per mode.</p></ul><p>These three-way methods extend the concept of PCA to multidimensional data, effectively capturing the inherent structure and correlations within such datasets. Their applications range from analytical chemistry to psychometrics and social sciences, reflecting their adaptability and power in extracting meaningful information from complex data structures.</p><h3 id="94-conclusions-and-recommendations"> <a href="#94-conclusions-and-recommendations" class="anchor-heading" aria-labelledby="94-conclusions-and-recommendations"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.4 Conclusions and Recommendations</h3><p>This chapter presents a variety of unsupervised multiblock methods, ranging from GSVD for shared variables to GPA and three-way methods like PARAFAC and Tucker for datasets with shared samples and variables. The choice of method depends on several factors:</p><ul><li><strong>Shared Modes</strong>: Whether the dataset involves shared variables, samples, or both.<li><strong>Number of Blocks</strong>: The complexity and number of data blocks involved.<li><strong>Data Homogeneity</strong>: Whether the data are homogeneous or heterogeneous.<li><strong>Need for Differentiation</strong>: Whether there is a need to differentiate between common, local, and distinct components.</ul><p>For instance, if the dataset consists of more than two blocks of homogeneous data and requires parsing out common, local, and distinct components, methods like SLIDE, GFA, and OnPLS are suitable choices. SLIDE and GFA are more similar to each other, focusing on simultaneous analysis, whereas OnPLS adopts a sequential approach to component extraction.</p><h3 id="941-open-issues"> <a href="#941-open-issues" class="anchor-heading" aria-labelledby="941-open-issues"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 9.4.1 Open Issues</h3><p>Despite the strengths of the methods discussed, there are several open issues:</p><ul><li><strong>Complexity of Methodology</strong>: The advanced statistical techniques, such as Bayesian estimation and the use of penalties, require significant expertise and careful tuning.<li><strong>Properties of Estimates</strong>: The stability and identifiability of the estimated parameters under various conditions remain areas of ongoing research.</ul><p>These challenges underscore the need for continued development and refinement in unsupervised multiblock data analysis techniques, ensuring their applicability and effectiveness in addressing complex, real-world data analysis scenarios.</p><h2 id="decision-trees"> <a href="#decision-trees" class="anchor-heading" aria-labelledby="decision-trees"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Decision trees</h2><p><strong>Matrix correlation methods</strong></p><p><img src="/assets/images/mbf_decision_tree_1.png" width="50%" /></p><p><strong>Unsupervised methods for the shared variable mode case and the shared sample mode case</strong></p><p><img src="/assets/images/mbf_decision_tree_2.png" width="50%" /></p><p><strong>ASCA-based methods</strong></p><p><img src="/assets/images/mbf_decision_tree_3.png" width="50%" /></p><p><strong>Alternative unsupervised method</strong></p><p><img src="/assets/images/mbf_decision_tree_4.png" width="50%" /></p><p><strong>Selecting a supervised method</strong></p><p><img src="/assets/images/mbf_decision_tree_5.png" width="50%" /></p><h2 id="method-list"> <a href="#method-list" class="anchor-heading" aria-labelledby="method-list"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Method list</h2><p><strong>Chapter 5: Unsupervised Methods in Selected Methods for Unsupervised and Supervised Topologies</strong></p><ol><li><strong>Simultaneous Component Analysis (SCA)</strong> - No specific citation provided.<li><strong>Distinct and Common Components Analysis (DCCA)</strong> - No specific citation provided.<li><strong>Multivariate Curve Resolution (MCR)</strong> - No specific citation provided.<li><strong>SUM-PCA</strong> - No specific citation provided.<li><strong>Multiple Factor Analysis (MFA)</strong> - No specific citation provided.<li><strong>Generalised Canonical Analysis (GCA)</strong> - No specific citation provided.<li><strong>Regularised Generalised Canonical Correlation Analysis (RGCCA)</strong> - No specific citation provided.<li><strong>Exponential Family SCA (ESCA)</strong> - No specific citation provided.<li><strong>Optimal-scaling (Optimal-SCA)</strong> - No specific citation provided.<li><strong>Joint and Individual Variation Explained (JIVE)</strong> - No specific citation provided.<li><strong>Advanced Coupled Matrix and Tensor Factorisation (ACMTF)</strong> - No specific citation provided.<li><strong>Penalised-ESCA (P-ESCA)</strong> - No specific citation provided.</ol><p><strong>Chapter 9: Alternative Unsupervised Methods</strong></p><ol><li><strong>Generalised Singular Value Decomposition (GSVD) also known as Quotient SVD (QSVD)</strong><ul><li>Van Loan, 1976; Paige and Saunders, 1981; De Moor and Zha, 1991.</ul><li><strong>Data Integration Analysis for Biomarker discovery using a Latent component method for Omics studies (DIABLO)</strong><ul><li>Singh et al., 2019.</ul><li><strong>Generalised Coupled Tensor Factorisation (GCTF)</strong><ul><li>Yılmaz et al., 2011; Şimşekli et al., 2013.</ul><li><strong>Extended PCA (XPCA)</strong><ul><li>Anderson-Bergman et al., 2018.</ul><li><strong>Structural Learning and Integrative Decomposition (SLIDE)</strong><ul><li>Gaynanova and Li, 2019.</ul><li><strong>Bayesian Inter-battery Factor Analysis (BIBFA)</strong><ul><li>Klami et al., 2013.</ul><li><strong>Group Factor Analysis (GFA)</strong><ul><li>Virtanen et al., 2012.</ul><li><strong>Orthogonal Projections to Latent Structures (OnPLS)</strong><ul><li>Löfstedt and Trygg, 2011.</ul><li><strong>Generalised Association Study (GAS)</strong><ul><li>Li and Gaynanova, 2018.</ul><li><strong>Multi-Omics Factor Analysis (MOFA)</strong><ul><li>Argelaguet et al., 2018.</ul><li><strong>Generalised Procrustes Analysis (GPA)</strong><ul><li>No specific citation provided.</ul><li><strong>Parallel Factor Analysis (PARAFAC)</strong><ul><li>No specific citation provided.</ul><li><strong>Tucker3 Model</strong><ul><li>No specific citation provided.</ul></ol><hr><footer><div class="d-flex mt-2"></div></footer></div></div><div class="search-overlay"></div></div>
